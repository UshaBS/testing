2019-06-25 11:11:15.341  INFO 4876 --- [main] c.L.SpringKafkaTutorialspointApplication : Starting SpringKafkaTutorialspointApplication on DIN69001166 with PID 4876 (C:\Users\agunture\Desktop\LatestlIB-master\Lib\target\classes started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 11:11:15.348  INFO 4876 --- [main] c.L.SpringKafkaTutorialspointApplication : No active profile set, falling back to default profiles: default
2019-06-25 11:11:15.876  INFO 4876 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 11:11:15.948  INFO 4876 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 67ms. Found 3 repository interfaces.
2019-06-25 11:11:16.193  INFO 4876 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$2987a18d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 11:11:16.241  INFO 4876 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$fa6d5509] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 11:11:16.286  INFO 4876 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 11:11:16.310  INFO 4876 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$55d5900a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 11:11:16.555  INFO 4876 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 9003 (http)
2019-06-25 11:11:16.575  INFO 4876 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-06-25 11:11:16.576  INFO 4876 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.17]
2019-06-25 11:11:16.806  INFO 4876 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-06-25 11:11:16.806  INFO 4876 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1408 ms
2019-06-25 11:11:16.959  INFO 4876 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 11:11:16.961  WARN 4876 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 11:11:17.101  INFO 4876 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 11:11:17.103  INFO 4876 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 11:11:17.140  INFO 4876 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 11:11:17.179  INFO 4876 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 11:11:17.180  INFO 4876 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 11:11:17.286  INFO 4876 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 11:11:17.382  INFO 4876 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 11:11:17.833  WARN 4876 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.SpringKafkaTutorialspointApplication.main(SpringKafkaTutorialspointApplication.java:21) ~[classes/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 35 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 40 common frames omitted

2019-06-25 11:11:17.843  INFO 4876 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@41bd6a0f'
2019-06-25 11:11:17.844  INFO 4876 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 11:11:18.084  INFO 4876 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 11:11:18.408  INFO 4876 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 11:11:18.438  WARN 4876 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 11:11:18.627  INFO 4876 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:2181]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-id
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 11:11:18.685  INFO 4876 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 11:11:18.685  INFO 4876 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 11:11:19.779  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:20.882  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:21.989  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:23.194  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:24.704  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:26.614  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:28.630  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:30.638  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:32.545  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:34.754  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:36.967  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:38.974  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:41.082  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:43.194  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:45.100  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:47.010  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:49.217  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:51.326  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:53.232  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:55.441  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:57.449  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:11:59.561  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:01.471  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:03.478  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:05.486  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:07.394  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:09.503  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:11.513  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:13.527  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:15.738  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:17.850  WARN 4876 --- [main] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-1, groupId=group-id] Connection to node -1 could not be established. Broker may not be available.
2019-06-25 11:12:18.779  WARN 4876 --- [main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'; nested exception is org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata
2019-06-25 11:12:18.779  INFO 4876 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-06-25 11:12:18.781  INFO 4876 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 11:12:18.782  INFO 4876 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 11:12:18.787  INFO 4876 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 11:12:18.788  INFO 4876 --- [main] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-06-25 11:12:18.796  INFO 4876 --- [main] ConditionEvaluationReportLoggingListener : 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-25 11:12:18.801 ERROR 4876 --- [main] o.s.boot.SpringApplication               : Application run failed

org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'; nested exception is org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:185) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:53) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:360) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:158) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:122) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:893) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:163) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.SpringKafkaTutorialspointApplication.main(SpringKafkaTutorialspointApplication.java:21) ~[classes/:na]
Caused by: org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata

2019-06-25 12:04:23.330  INFO 8316 --- [main] com.cg.Lib.LibApplication                : Starting LibApplication on DIN69001166 with PID 8316 (C:\Users\agunture\Desktop\LatestlIB-master\Lib\target\classes started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 12:04:23.332  INFO 8316 --- [main] com.cg.Lib.LibApplication                : No active profile set, falling back to default profiles: default
2019-06-25 12:04:23.832  INFO 8316 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 12:04:23.906  INFO 8316 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 69ms. Found 3 repository interfaces.
2019-06-25 12:04:24.115  INFO 8316 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$a617a273] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 12:04:24.176  INFO 8316 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$76fd55ef] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 12:04:24.196  INFO 8316 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 12:04:24.218  INFO 8316 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d26590f0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 12:04:24.472  INFO 8316 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 9003 (http)
2019-06-25 12:04:24.492  INFO 8316 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-06-25 12:04:24.493  INFO 8316 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.17]
2019-06-25 12:04:24.863  INFO 8316 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-06-25 12:04:24.863  INFO 8316 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1504 ms
2019-06-25 12:04:24.982  INFO 8316 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 12:04:24.984  WARN 8316 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 12:04:25.115  INFO 8316 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 12:04:25.117  INFO 8316 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 12:04:25.161  INFO 8316 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 12:04:25.207  INFO 8316 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 12:04:25.208  INFO 8316 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 12:04:25.313  INFO 8316 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 12:04:25.421  INFO 8316 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 12:04:25.869  WARN 8316 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 35 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 40 common frames omitted

2019-06-25 12:04:25.876  INFO 8316 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@83e635f'
2019-06-25 12:04:25.878  INFO 8316 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 12:04:25.909  WARN 8316 --- [main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
2019-06-25 12:04:25.909  INFO 8316 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 12:04:25.912  INFO 8316 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 12:04:25.916  INFO 8316 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 12:04:25.917  INFO 8316 --- [main] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-06-25 12:04:25.926  INFO 8316 --- [main] ConditionEvaluationReportLoggingListener : 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-25 12:04:25.932 ERROR 8316 --- [main] o.s.boot.SpringApplication               : Application run failed

org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:380) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:172) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:124) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:237) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:211) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:175) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:851) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1188) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 17 common frames omitted

2019-06-25 12:43:59.578  INFO 10904 --- [main] com.cg.Lib.LibApplication                : Starting LibApplication on DIN69001166 with PID 10904 (C:\Users\agunture\Desktop\LatestlIB-master\Lib\target\classes started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 12:43:59.581  INFO 10904 --- [main] com.cg.Lib.LibApplication                : No active profile set, falling back to default profiles: default
2019-06-25 12:44:00.106  INFO 10904 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 12:44:00.166  INFO 10904 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 55ms. Found 3 repository interfaces.
2019-06-25 12:44:00.381  INFO 10904 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$2007f3b7] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 12:44:00.431  INFO 10904 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$f0eda733] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 12:44:00.455  INFO 10904 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 12:44:00.479  INFO 10904 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4c55e234] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 12:44:00.728  INFO 10904 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 9003 (http)
2019-06-25 12:44:00.748  INFO 10904 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-06-25 12:44:00.748  INFO 10904 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.17]
2019-06-25 12:44:00.979  INFO 10904 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-06-25 12:44:00.979  INFO 10904 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1368 ms
2019-06-25 12:44:01.104  INFO 10904 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 12:44:01.105  WARN 10904 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 12:44:01.237  INFO 10904 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 12:44:01.240  INFO 10904 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 12:44:01.282  INFO 10904 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 12:44:01.331  INFO 10904 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 12:44:01.332  INFO 10904 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 12:44:01.429  INFO 10904 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 12:44:01.538  INFO 10904 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 12:44:01.983  WARN 10904 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 35 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 40 common frames omitted

2019-06-25 12:44:01.990  INFO 10904 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@30a62a5b'
2019-06-25 12:44:01.992  INFO 10904 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 12:44:02.022  WARN 10904 --- [main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'spring.embedded.kafka.brokers' in value "${spring.embedded.kafka.brokers}"
2019-06-25 12:44:02.022  INFO 10904 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 12:44:02.025  INFO 10904 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 12:44:02.029  INFO 10904 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 12:44:02.030  INFO 10904 --- [main] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-06-25 12:44:02.039  INFO 10904 --- [main] ConditionEvaluationReportLoggingListener : 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-25 12:44:02.045 ERROR 10904 --- [main] o.s.boot.SpringApplication               : Application run failed

org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'spring.embedded.kafka.brokers' in value "${spring.embedded.kafka.brokers}"
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:380) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'spring.embedded.kafka.brokers' in value "${spring.embedded.kafka.brokers}"
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:172) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:124) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:237) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:211) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveNestedPlaceholders(AbstractPropertyResolver.java:228) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.PropertySourcesPropertyResolver.getProperty(PropertySourcesPropertyResolver.java:88) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.PropertySourcesPropertyResolver.getProperty(PropertySourcesPropertyResolver.java:62) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractEnvironment.getProperty(AbstractEnvironment.java:539) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer$1.getProperty(PropertySourcesPlaceholderConfigurer.java:137) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer$1.getProperty(PropertySourcesPlaceholderConfigurer.java:133) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.PropertySourcesPropertyResolver.getProperty(PropertySourcesPropertyResolver.java:85) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.PropertySourcesPropertyResolver.getPropertyAsRawString(PropertySourcesPropertyResolver.java:74) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:145) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:124) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:237) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:211) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:175) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:851) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1188) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 17 common frames omitted

2019-06-25 16:19:42.143  INFO 11616 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1590 ms
2019-06-25 16:19:42.276  WARN 11616 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 16:19:43.155  WARN 11616 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 35 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 40 common frames omitted

2019-06-25 16:19:43.197  WARN 11616 --- [main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
2019-06-25 16:19:43.223 ERROR 11616 --- [main] o.s.boot.SpringApplication               : Application run failed

org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:380) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:172) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:124) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:237) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:211) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:175) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:851) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1188) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 17 common frames omitted

2019-06-25 16:21:04.881  INFO 12028 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1296 ms
2019-06-25 16:21:04.996  WARN 12028 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 16:21:05.830  WARN 12028 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 35 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 40 common frames omitted

2019-06-25 16:21:05.870  WARN 12028 --- [main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
2019-06-25 16:21:05.896 ERROR 12028 --- [main] o.s.boot.SpringApplication               : Application run failed

org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:380) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:172) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:124) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:237) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:211) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:175) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:851) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1188) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 17 common frames omitted

2019-06-25 16:48:28.627  INFO 8640 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1266 ms
2019-06-25 16:48:28.753  WARN 8640 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 16:48:29.581  WARN 8640 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 35 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 40 common frames omitted

2019-06-25 16:48:29.628  WARN 8640 --- [main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
2019-06-25 16:48:29.659 ERROR 8640 --- [main] o.s.boot.SpringApplication               : Application run failed

org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:380) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:172) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:124) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:237) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:211) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:175) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:851) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1188) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 17 common frames omitted

2019-06-25 16:56:12.964  INFO 3420 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1297 ms
2019-06-25 16:56:13.084  WARN 3420 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 16:56:13.928  WARN 3420 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 35 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 40 common frames omitted

2019-06-25 16:56:13.959  WARN 3420 --- [main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
2019-06-25 16:56:13.990 ERROR 3420 --- [main] o.s.boot.SpringApplication               : Application run failed

org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'receiverConfig': Injection of autowired dependencies failed; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:380) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at com.cg.Lib.LibApplication.main(LibApplication.java:16) ~[classes/:na]
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'kafka.bootstrap-servers' in value "${kafka.bootstrap-servers}"
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:172) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:124) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:237) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:211) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:175) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:851) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1188) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 17 common frames omitted

2019-06-25 18:21:36.390  INFO 4500 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Starting SpringKafkaApplicationTest on DIN69001166 with PID 4500 (started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 18:21:36.390  INFO 4500 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : No active profile set, falling back to default profiles: default
2019-06-25 18:21:37.187  INFO 4500 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 18:21:37.286  INFO 4500 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 94ms. Found 3 repository interfaces.
2019-06-25 18:21:37.677  INFO 4500 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$a176c269] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:21:37.786  INFO 4500 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$725c75e5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:21:37.849  INFO 4500 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 18:21:37.864  INFO 4500 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$cdc4b0e6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:21:38.130  INFO 4500 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 18:21:38.145  WARN 4500 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 18:21:38.395  INFO 4500 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 18:21:38.399  INFO 4500 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 18:21:38.492  INFO 4500 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 18:21:38.555  INFO 4500 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 18:21:38.555  INFO 4500 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 18:21:38.758  INFO 4500 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 18:21:38.899  INFO 4500 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 18:21:39.617  WARN 4500 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) ~[junit-4.12.jar:4.12]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) ~[.cp/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 61 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 66 common frames omitted

2019-06-25 18:21:39.620  INFO 4500 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@4fea23d6'
2019-06-25 18:21:39.620  INFO 4500 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:21:40.026  INFO 4500 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 18:21:41.104  INFO 4500 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 18:21:41.174  WARN 4500 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 18:21:41.846  INFO 4500 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61395]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:21:41.893  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:21:41.893  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:21:41.908  INFO 4500 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: m9hzrYDYS1-BEA_0Bm5_-Q
2019-06-25 18:21:41.940  INFO 4500 --- [ProcessThread(sid:0 cport:61386):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100007f72330001 type:setData cxid:0x50 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/helloworld.t Error:KeeperErrorCode = NoNode for /config/topics/helloworld.t
2019-06-25 18:21:42.018  INFO 4500 --- [kafka-request-handler-3] kafka.zk.AdminZkClient                   : Topic creation Map(helloworld.t-0 -> ArrayBuffer(0))
2019-06-25 18:21:42.033  INFO 4500 --- [kafka-request-handler-3] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic helloworld.t with 1 partitions and replication factor 1 is successful
2019-06-25 18:21:42.033  INFO 4500 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(helloworld.t)], deleted topics: [Set()], new partition replica assignment [Map(helloworld.t-0 -> Vector(0))]
2019-06-25 18:21:42.033  INFO 4500 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for helloworld.t-0
2019-06-25 18:21:42.096  INFO 4500 --- [kafka-request-handler-6] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions helloworld.t-0
2019-06-25 18:21:42.112  INFO 4500 --- [kafka-request-handler-6] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Loading producer state till offset 0 with message format version 2
2019-06-25 18:21:42.128  INFO 4500 --- [kafka-request-handler-6] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms
2019-06-25 18:21:42.128  INFO 4500 --- [kafka-request-handler-6] kafka.log.LogManager                     : Created log for partition helloworld.t-0 in C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:21:42.128  INFO 4500 --- [kafka-request-handler-6] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] No checkpointed highwatermark is found for partition helloworld.t-0
2019-06-25 18:21:42.128  INFO 4500 --- [kafka-request-handler-6] kafka.cluster.Replica                    : Replica loaded for partition helloworld.t-0 with initial high watermark 0
2019-06-25 18:21:42.128  INFO 4500 --- [kafka-request-handler-6] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] helloworld.t-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:21:42.175  INFO 4500 --- [kafka-request-handler-6] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:21:42.269  INFO 4500 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61395]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:21:42.269  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:21:42.269  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:21:42.269  INFO 4500 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:21:42.284  INFO 4500 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Started SpringKafkaApplicationTest in 6.301 seconds (JVM running for 12.812)
2019-06-25 18:21:42.300  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: m9hzrYDYS1-BEA_0Bm5_-Q
2019-06-25 18:21:42.315  INFO 4500 --- [ProcessThread(sid:0 cport:61386):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100007f72330001 type:setData cxid:0x60 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-06-25 18:21:42.362  INFO 4500 --- [kafka-request-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-06-25 18:21:42.394  INFO 4500 --- [kafka-request-handler-1] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-06-25 18:21:42.394  INFO 4500 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-06-25 18:21:42.394  INFO 4500 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:21:42.566  INFO 4500 --- [kafka-request-handler-7] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:21:42.612  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Loading producer state till offset 0 with message format version 2
2019-06-25 18:21:42.612  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms
2019-06-25 18:21:42.612  INFO 4500 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:21:42.612  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-06-25 18:21:42.612  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-06-25 18:21:42.612  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:21:42.722  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Loading producer state till offset 0 with message format version 2
2019-06-25 18:21:42.722  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms
2019-06-25 18:21:42.722  INFO 4500 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:21:42.722  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-06-25 18:21:42.722  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-06-25 18:21:42.722  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:21:42.831  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Loading producer state till offset 0 with message format version 2
2019-06-25 18:21:42.831  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms
2019-06-25 18:21:42.831  INFO 4500 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:21:42.831  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-06-25 18:21:42.831  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-06-25 18:21:42.831  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:21:42.925  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Loading producer state till offset 0 with message format version 2
2019-06-25 18:21:42.941  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms
2019-06-25 18:21:42.941  INFO 4500 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:21:42.941  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-06-25 18:21:42.941  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-06-25 18:21:42.941  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:21:43.066  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Loading producer state till offset 0 with message format version 2
2019-06-25 18:21:43.066  INFO 4500 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms
2019-06-25 18:21:43.066  INFO 4500 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:21:43.066  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-06-25 18:21:43.066  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-06-25 18:21:43.066  INFO 4500 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:21:43.159  INFO 4500 --- [kafka-request-handler-7] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:21:43.163  INFO 4500 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-06-25 18:21:43.163  INFO 4500 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-06-25 18:21:43.163  INFO 4500 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-06-25 18:21:43.163  INFO 4500 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-06-25 18:21:43.163  INFO 4500 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-06-25 18:21:43.178  INFO 4500 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 15 milliseconds.
2019-06-25 18:21:43.178  INFO 4500 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2019-06-25 18:21:43.178  INFO 4500 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2019-06-25 18:21:43.178  INFO 4500 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-06-25 18:21:43.178  INFO 4500 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2019-06-25 18:21:43.178  INFO 4500 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61395]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:21:43.178  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Discovered group coordinator localhost:61395 (id: 2147483647 rack: null)
2019-06-25 18:21:43.178  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Revoking previously assigned partitions []
2019-06-25 18:21:43.178  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:21:43.178  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] (Re-)joining group
2019-06-25 18:21:43.194  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:21:43.194  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:21:43.194  INFO 4500 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: m9hzrYDYS1-BEA_0Bm5_-Q
2019-06-25 18:21:43.210  INFO 4500 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61395]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:21:43.210  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:21:43.210  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:21:43.210  INFO 4500 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:21:43.225  INFO 4500 --- [-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: m9hzrYDYS1-BEA_0Bm5_-Q
2019-06-25 18:21:43.225  INFO 4500 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Discovered group coordinator localhost:61395 (id: 2147483647 rack: null)
2019-06-25 18:21:43.225  INFO 4500 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Revoking previously assigned partitions []
2019-06-25 18:21:43.225  INFO 4500 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:21:43.225  INFO 4500 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] (Re-)joining group
2019-06-25 18:21:43.241  INFO 4500 --- [kafka-request-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 0 (__consumer_offsets-2)
2019-06-25 18:21:43.241  INFO 4500 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 0 (__consumer_offsets-0)
2019-06-25 18:21:43.241  INFO 4500 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group helloworld generation 1 (__consumer_offsets-2)
2019-06-25 18:21:43.256  INFO 4500 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group helloworld for generation 1
2019-06-25 18:21:43.256  INFO 4500 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group sender generation 1 (__consumer_offsets-0)
2019-06-25 18:21:43.256  INFO 4500 --- [kafka-request-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group sender for generation 1
2019-06-25 18:21:43.335  INFO 4500 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Successfully joined group with generation 1
2019-06-25 18:21:43.335  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Successfully joined group with generation 1
2019-06-25 18:21:43.335  INFO 4500 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Setting newly assigned partitions [sender.t-1, sender.t-0]
2019-06-25 18:21:43.335  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Setting newly assigned partitions [helloworld.t-0]
2019-06-25 18:21:43.366  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:21:43.366  INFO 4500 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-1 to offset 0.
2019-06-25 18:21:43.366  INFO 4500 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-0 to offset 0.
2019-06-25 18:21:43.366  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0]
2019-06-25 18:21:43.381  INFO 4500 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [sender.t-1, sender.t-0]
2019-06-25 18:21:43.413  INFO 4500 --- [main] com.cg.Lib.producer.Sender               : sending payload='Hello Spring Kafka Sender!'
2019-06-25 18:21:43.413  INFO 4500 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:61395]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-25 18:21:43.428  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:21:43.428  INFO 4500 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:21:43.444  INFO 4500 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: m9hzrYDYS1-BEA_0Bm5_-Q
2019-06-25 18:21:43.538  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.cg.Lib.consumer.Receiver             : received payload='Hello Spring Kafka Sender!'
2019-06-25 18:21:53.461  INFO 4500 --- [-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:21:53.469  INFO 4500 --- [kafka-request-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 1 (__consumer_offsets-0)
2019-06-25 18:21:53.469  INFO 4500 --- [kafka-request-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group sender with generation 2 is now empty (__consumer_offsets-0)
2019-06-25 18:21:53.485  INFO 4500 --- [-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:21:53.516  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:21:53.516  INFO 4500 --- [kafka-request-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 1 (__consumer_offsets-2)
2019-06-25 18:21:53.516  INFO 4500 --- [kafka-request-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group helloworld with generation 2 is now empty (__consumer_offsets-2)
2019-06-25 18:21:53.532  INFO 4500 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:21:53.532  INFO 4500 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-06-25 18:21:53.532  INFO 4500 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-06-25 18:21:53.532  INFO 4500 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:21:53.532  INFO 4500 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 18:21:53.532  INFO 4500 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 18:21:53.532  INFO 4500 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2019-06-25 18:21:53.532  INFO 4500 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Starting controlled shutdown
2019-06-25 18:21:53.547  INFO 4500 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] Shutting down broker 0
2019-06-25 18:21:53.563  INFO 4500 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Controlled shutdown succeeded
2019-06-25 18:21:53.563  INFO 4500 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2019-06-25 18:21:53.563  INFO 4500 --- [/config/changes-event-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2019-06-25 18:21:53.563  INFO 4500 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2019-06-25 18:21:53.563  INFO 4500 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopping socket server request processors
2019-06-25 18:21:53.563  INFO 4500 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopped socket server request processors
2019-06-25 18:21:53.579  INFO 4500 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shutting down
2019-06-25 18:21:53.579  INFO 4500 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shut down completely
2019-06-25 18:21:53.579  INFO 4500 --- [main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2019-06-25 18:21:53.579  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2019-06-25 18:21:53.641  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2019-06-25 18:21:53.641  INFO 4500 --- [ExpirationReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2019-06-25 18:21:53.641  INFO 4500 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2019-06-25 18:21:53.641  INFO 4500 --- [main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2019-06-25 18:21:53.641  INFO 4500 --- [main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2019-06-25 18:21:53.641  INFO 4500 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutting down
2019-06-25 18:21:53.641  INFO 4500 --- [TxnMarkerSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Stopped
2019-06-25 18:21:53.641  INFO 4500 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutdown completed
2019-06-25 18:21:53.641  INFO 4500 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2019-06-25 18:21:53.641  INFO 4500 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2019-06-25 18:21:53.641  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2019-06-25 18:21:53.735  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2019-06-25 18:21:53.735  INFO 4500 --- [ExpirationReaper-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2019-06-25 18:21:53.735  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2019-06-25 18:21:53.844  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2019-06-25 18:21:53.844  INFO 4500 --- [ExpirationReaper-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2019-06-25 18:21:53.844  INFO 4500 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2019-06-25 18:21:53.844  INFO 4500 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2019-06-25 18:21:53.844  INFO 4500 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2019-06-25 18:21:53.844  INFO 4500 --- [LogDirFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2019-06-25 18:21:53.844  INFO 4500 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2019-06-25 18:21:53.844  INFO 4500 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2019-06-25 18:21:53.844  INFO 4500 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2019-06-25 18:21:53.844  INFO 4500 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutting down
2019-06-25 18:21:53.860  INFO 4500 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2019-06-25 18:21:53.860  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2019-06-25 18:21:54.048  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2019-06-25 18:21:54.048  INFO 4500 --- [ExpirationReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2019-06-25 18:21:54.048  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2019-06-25 18:21:54.141  INFO 4500 --- [ExpirationReaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2019-06-25 18:21:54.141  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2019-06-25 18:21:54.141  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2019-06-25 18:21:54.344  INFO 4500 --- [ExpirationReaper-0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2019-06-25 18:21:54.344  INFO 4500 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2019-06-25 18:21:54.376  INFO 4500 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2019-06-25 18:21:54.376  INFO 4500 --- [main] kafka.log.LogManager                     : Shutting down.
2019-06-25 18:21:54.391  INFO 4500 --- [main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2019-06-25 18:21:54.391  INFO 4500 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2019-06-25 18:21:54.391  INFO 4500 --- [kafka-log-cleaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2019-06-25 18:21:54.391  INFO 4500 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2019-06-25 18:21:54.454  INFO 4500 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=helloworld.t-0] Writing producer snapshot at offset 1
2019-06-25 18:21:54.501  INFO 4500 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 4
2019-06-25 18:21:54.531  INFO 4500 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 4
2019-06-25 18:21:54.687  INFO 4500 --- [main] kafka.log.LogManager                     : Shutdown complete.
2019-06-25 18:21:54.687  INFO 4500 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2019-06-25 18:21:54.687  INFO 4500 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2019-06-25 18:21:54.687  INFO 4500 --- [main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2019-06-25 18:21:54.687  INFO 4500 --- [main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=0] Stopped partition state machine
2019-06-25 18:21:54.687  INFO 4500 --- [main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2019-06-25 18:21:54.687  INFO 4500 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2019-06-25 18:21:54.687  INFO 4500 --- [Controller-0-to-broker-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2019-06-25 18:21:54.687  INFO 4500 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2019-06-25 18:21:54.687  INFO 4500 --- [main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2019-06-25 18:21:54.687  INFO 4500 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2019-06-25 18:21:54.687  INFO 4500 --- [ProcessThread(sid:0 cport:61386):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100007f72330001
2019-06-25 18:21:54.719  INFO 4500 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100007f72330001 closed
2019-06-25 18:21:54.719  WARN 4500 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Unable to read additional data from client sessionid 0x100007f72330001, likely client has closed socket
2019-06-25 18:21:54.719  INFO 4500 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61392 which had sessionid 0x100007f72330001
2019-06-25 18:21:54.719  INFO 4500 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100007f72330001
2019-06-25 18:21:54.719  INFO 4500 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2019-06-25 18:21:54.719  INFO 4500 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2019-06-25 18:21:55.422  INFO 4500 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2019-06-25 18:21:55.422  INFO 4500 --- [ThrottledChannelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2019-06-25 18:21:55.422  INFO 4500 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2019-06-25 18:21:56.422  INFO 4500 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2019-06-25 18:21:56.422  INFO 4500 --- [ThrottledChannelReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2019-06-25 18:21:56.422  INFO 4500 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2019-06-25 18:21:57.424  INFO 4500 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2019-06-25 18:21:57.424  INFO 4500 --- [ThrottledChannelReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2019-06-25 18:21:57.426  INFO 4500 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutting down socket server
2019-06-25 18:21:57.441  INFO 4500 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutdown completed
2019-06-25 18:21:57.441  INFO 4500 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2019-06-25 18:21:57.457  INFO 4500 --- [ZkClient-EventThread-20-127.0.0.1:61386] org.I0Itec.zkclient.ZkEventThread        : Terminate ZkClient event thread.
2019-06-25 18:21:57.457  INFO 4500 --- [ProcessThread(sid:0 cport:61386):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100007f72330000
2019-06-25 18:21:57.473  INFO 4500 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100007f72330000 closed
2019-06-25 18:21:57.473  INFO 4500 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100007f72330000
2019-06-25 18:21:57.489  INFO 4500 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61389 which had sessionid 0x100007f72330000
2019-06-25 18:21:57.489  INFO 4500 --- [main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2019-06-25 18:21:57.489  INFO 4500 --- [main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2019-06-25 18:21:57.489  INFO 4500 --- [main] o.a.z.server.PrepRequestProcessor        : Shutting down
2019-06-25 18:21:57.489  INFO 4500 --- [main] o.a.z.server.SyncRequestProcessor        : Shutting down
2019-06-25 18:21:57.489  INFO 4500 --- [ProcessThread(sid:0 cport:61386):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2019-06-25 18:21:57.489  INFO 4500 --- [SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2019-06-25 18:21:57.489  INFO 4500 --- [main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2019-06-25 18:21:57.489  INFO 4500 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2019-06-25 18:21:57.942  INFO 4500 --- [SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2019-06-25 18:21:58.557 ERROR 4500 --- [Thread-3] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-2493220975144945071\helloworld.t-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:21:58.557 ERROR 4500 --- [Thread-0] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-12927362439554146701

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-12927362439554146701\version-2\log.1: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:24:34.483  INFO 10928 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Starting SpringKafkaApplicationTest on DIN69001166 with PID 10928 (started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 18:24:34.483  INFO 10928 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : No active profile set, falling back to default profiles: default
2019-06-25 18:24:35.217  INFO 10928 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 18:24:35.298  INFO 10928 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 78ms. Found 3 repository interfaces.
2019-06-25 18:24:35.641  INFO 10928 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$aa78d38d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:24:35.735  INFO 10928 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$7b5e8709] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:24:35.782  INFO 10928 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 18:24:35.813  INFO 10928 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d6c6c20a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:24:36.048  INFO 10928 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 18:24:36.048  WARN 10928 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 18:24:36.267  INFO 10928 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 18:24:36.277  INFO 10928 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 18:24:36.339  INFO 10928 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 18:24:36.417  INFO 10928 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 18:24:36.417  INFO 10928 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 18:24:36.558  INFO 10928 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 18:24:36.714  INFO 10928 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 18:24:37.386  WARN 10928 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) ~[junit-4.12.jar:4.12]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) ~[.cp/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 61 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 66 common frames omitted

2019-06-25 18:24:37.397  INFO 10928 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@6b9fc5c7'
2019-06-25 18:24:37.397  INFO 10928 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:24:37.709  INFO 10928 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 18:24:38.631  INFO 10928 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 18:24:38.690  WARN 10928 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 18:24:39.346  INFO 10928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61457]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:24:39.377  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:24:39.377  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:24:39.393  INFO 10928 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: pzm4aJacTEqpL1NsAHaEPw
2019-06-25 18:24:39.408  INFO 10928 --- [ProcessThread(sid:0 cport:61448):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1000082308d0001 type:setData cxid:0x50 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/helloworld.t Error:KeeperErrorCode = NoNode for /config/topics/helloworld.t
2019-06-25 18:24:39.455  INFO 10928 --- [kafka-request-handler-5] kafka.zk.AdminZkClient                   : Topic creation Map(helloworld.t-0 -> ArrayBuffer(0))
2019-06-25 18:24:39.471  INFO 10928 --- [kafka-request-handler-5] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic helloworld.t with 1 partitions and replication factor 1 is successful
2019-06-25 18:24:39.487  INFO 10928 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(helloworld.t)], deleted topics: [Set()], new partition replica assignment [Map(helloworld.t-0 -> Vector(0))]
2019-06-25 18:24:39.487  INFO 10928 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for helloworld.t-0
2019-06-25 18:24:39.533  INFO 10928 --- [kafka-request-handler-6] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions helloworld.t-0
2019-06-25 18:24:39.549  INFO 10928 --- [kafka-request-handler-6] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Loading producer state till offset 0 with message format version 2
2019-06-25 18:24:39.549  INFO 10928 --- [kafka-request-handler-6] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms
2019-06-25 18:24:39.549  INFO 10928 --- [kafka-request-handler-6] kafka.log.LogManager                     : Created log for partition helloworld.t-0 in C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:24:39.549  INFO 10928 --- [kafka-request-handler-6] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] No checkpointed highwatermark is found for partition helloworld.t-0
2019-06-25 18:24:39.549  INFO 10928 --- [kafka-request-handler-6] kafka.cluster.Replica                    : Replica loaded for partition helloworld.t-0 with initial high watermark 0
2019-06-25 18:24:39.549  INFO 10928 --- [kafka-request-handler-6] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] helloworld.t-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:24:39.612  INFO 10928 --- [kafka-request-handler-6] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:24:39.752  INFO 10928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61457]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:24:39.769  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:24:39.769  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:24:39.769  INFO 10928 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:24:39.784  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: pzm4aJacTEqpL1NsAHaEPw
2019-06-25 18:24:39.784  INFO 10928 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Started SpringKafkaApplicationTest in 5.583 seconds (JVM running for 10.007)
2019-06-25 18:24:39.800  INFO 10928 --- [ProcessThread(sid:0 cport:61448):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1000082308d0001 type:setData cxid:0x60 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-06-25 18:24:39.878  INFO 10928 --- [kafka-request-handler-3] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-06-25 18:24:39.909  INFO 10928 --- [kafka-request-handler-3] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-06-25 18:24:39.909  INFO 10928 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-06-25 18:24:39.925  INFO 10928 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:24:40.050  INFO 10928 --- [kafka-request-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:24:40.066  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Loading producer state till offset 0 with message format version 2
2019-06-25 18:24:40.066  INFO 10928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61457]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:24:40.066  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms
2019-06-25 18:24:40.066  INFO 10928 --- [kafka-request-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:24:40.066  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-06-25 18:24:40.066  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-06-25 18:24:40.066  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:24:40.081  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:24:40.081  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:24:40.081  INFO 10928 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: pzm4aJacTEqpL1NsAHaEPw
2019-06-25 18:24:40.081  INFO 10928 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61457]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:24:40.097  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:24:40.097  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:24:40.097  INFO 10928 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:24:40.112  INFO 10928 --- [-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: pzm4aJacTEqpL1NsAHaEPw
2019-06-25 18:24:40.144  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Loading producer state till offset 0 with message format version 2
2019-06-25 18:24:40.144  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms
2019-06-25 18:24:40.159  INFO 10928 --- [kafka-request-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:24:40.159  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-06-25 18:24:40.159  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-06-25 18:24:40.159  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:24:40.206  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Loading producer state till offset 0 with message format version 2
2019-06-25 18:24:40.222  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms
2019-06-25 18:24:40.222  INFO 10928 --- [kafka-request-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:24:40.222  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-06-25 18:24:40.222  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-06-25 18:24:40.222  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:24:40.284  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Loading producer state till offset 0 with message format version 2
2019-06-25 18:24:40.284  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms
2019-06-25 18:24:40.284  INFO 10928 --- [kafka-request-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:24:40.284  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-06-25 18:24:40.284  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-06-25 18:24:40.284  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:24:40.347  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Loading producer state till offset 0 with message format version 2
2019-06-25 18:24:40.347  INFO 10928 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms
2019-06-25 18:24:40.347  INFO 10928 --- [kafka-request-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:24:40.347  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-06-25 18:24:40.347  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-06-25 18:24:40.347  INFO 10928 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:24:40.394  INFO 10928 --- [kafka-request-handler-3] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:24:40.409  INFO 10928 --- [kafka-request-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-06-25 18:24:40.409  INFO 10928 --- [kafka-request-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-06-25 18:24:40.409  INFO 10928 --- [kafka-request-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-06-25 18:24:40.409  INFO 10928 --- [kafka-request-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-06-25 18:24:40.409  INFO 10928 --- [kafka-request-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-06-25 18:24:40.409  INFO 10928 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds.
2019-06-25 18:24:40.409  INFO 10928 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2019-06-25 18:24:40.409  INFO 10928 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2019-06-25 18:24:40.409  INFO 10928 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-06-25 18:24:40.409  INFO 10928 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2019-06-25 18:24:40.441  INFO 10928 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Discovered group coordinator localhost:61457 (id: 2147483647 rack: null)
2019-06-25 18:24:40.441  INFO 10928 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Revoking previously assigned partitions []
2019-06-25 18:24:40.441  INFO 10928 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:24:40.441  INFO 10928 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] (Re-)joining group
2019-06-25 18:24:40.456  INFO 10928 --- [kafka-request-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 0 (__consumer_offsets-0)
2019-06-25 18:24:40.456  INFO 10928 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group sender generation 1 (__consumer_offsets-0)
2019-06-25 18:24:40.472  INFO 10928 --- [kafka-request-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group sender for generation 1
2019-06-25 18:24:40.487  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Discovered group coordinator localhost:61457 (id: 2147483647 rack: null)
2019-06-25 18:24:40.487  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Revoking previously assigned partitions []
2019-06-25 18:24:40.487  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:24:40.487  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] (Re-)joining group
2019-06-25 18:24:40.487  INFO 10928 --- [kafka-request-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 0 (__consumer_offsets-2)
2019-06-25 18:24:40.487  INFO 10928 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group helloworld generation 1 (__consumer_offsets-2)
2019-06-25 18:24:40.487  INFO 10928 --- [kafka-request-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group helloworld for generation 1
2019-06-25 18:24:40.534  INFO 10928 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Successfully joined group with generation 1
2019-06-25 18:24:40.534  INFO 10928 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Setting newly assigned partitions [sender.t-1, sender.t-0]
2019-06-25 18:24:40.534  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Successfully joined group with generation 1
2019-06-25 18:24:40.534  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Setting newly assigned partitions [helloworld.t-0]
2019-06-25 18:24:40.550  INFO 10928 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-1 to offset 0.
2019-06-25 18:24:40.550  INFO 10928 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-0 to offset 0.
2019-06-25 18:24:40.550  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:24:40.550  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0]
2019-06-25 18:24:40.566  INFO 10928 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [sender.t-1, sender.t-0]
2019-06-25 18:24:40.612  INFO 10928 --- [main] com.cg.Lib.producer.Sender               : sending payload='Hello Spring Kafka Sender!'
2019-06-25 18:24:40.612  INFO 10928 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:61457]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-25 18:24:40.628  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:24:40.628  INFO 10928 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:24:40.628  INFO 10928 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: pzm4aJacTEqpL1NsAHaEPw
2019-06-25 18:24:40.675  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.cg.Lib.consumer.Receiver             : received payload='Hello Spring Kafka Sender!'
2019-06-25 18:24:50.650  INFO 10928 --- [-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:24:50.661  INFO 10928 --- [kafka-request-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 1 (__consumer_offsets-0)
2019-06-25 18:24:50.661  INFO 10928 --- [kafka-request-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group sender with generation 2 is now empty (__consumer_offsets-0)
2019-06-25 18:24:50.661  INFO 10928 --- [-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:24:50.677  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:24:50.677  INFO 10928 --- [kafka-request-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 1 (__consumer_offsets-2)
2019-06-25 18:24:50.677  INFO 10928 --- [kafka-request-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group helloworld with generation 2 is now empty (__consumer_offsets-2)
2019-06-25 18:24:50.677  INFO 10928 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:24:50.677  INFO 10928 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-06-25 18:24:50.677  INFO 10928 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-06-25 18:24:50.677  INFO 10928 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:24:50.677  INFO 10928 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 18:24:50.692  INFO 10928 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 18:24:50.692  INFO 10928 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2019-06-25 18:24:50.692  INFO 10928 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Starting controlled shutdown
2019-06-25 18:24:50.708  INFO 10928 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] Shutting down broker 0
2019-06-25 18:24:50.708  INFO 10928 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Controlled shutdown succeeded
2019-06-25 18:24:50.708  INFO 10928 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2019-06-25 18:24:50.708  INFO 10928 --- [/config/changes-event-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2019-06-25 18:24:50.708  INFO 10928 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2019-06-25 18:24:50.708  INFO 10928 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopping socket server request processors
2019-06-25 18:24:50.724  INFO 10928 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopped socket server request processors
2019-06-25 18:24:50.724  INFO 10928 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shutting down
2019-06-25 18:24:50.724  INFO 10928 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shut down completely
2019-06-25 18:24:50.739  INFO 10928 --- [main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2019-06-25 18:24:50.739  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2019-06-25 18:24:50.864  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2019-06-25 18:24:50.864  INFO 10928 --- [ExpirationReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2019-06-25 18:24:50.864  INFO 10928 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2019-06-25 18:24:50.864  INFO 10928 --- [main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2019-06-25 18:24:50.864  INFO 10928 --- [main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2019-06-25 18:24:50.864  INFO 10928 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutting down
2019-06-25 18:24:50.864  INFO 10928 --- [TxnMarkerSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Stopped
2019-06-25 18:24:50.864  INFO 10928 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutdown completed
2019-06-25 18:24:50.864  INFO 10928 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2019-06-25 18:24:50.880  INFO 10928 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2019-06-25 18:24:50.880  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2019-06-25 18:24:51.068  INFO 10928 --- [ExpirationReaper-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2019-06-25 18:24:51.068  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2019-06-25 18:24:51.068  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2019-06-25 18:24:51.271  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2019-06-25 18:24:51.271  INFO 10928 --- [ExpirationReaper-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2019-06-25 18:24:51.271  INFO 10928 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2019-06-25 18:24:51.271  INFO 10928 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2019-06-25 18:24:51.271  INFO 10928 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2019-06-25 18:24:51.271  INFO 10928 --- [LogDirFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2019-06-25 18:24:51.271  INFO 10928 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2019-06-25 18:24:51.271  INFO 10928 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2019-06-25 18:24:51.271  INFO 10928 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2019-06-25 18:24:51.271  INFO 10928 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutting down
2019-06-25 18:24:51.271  INFO 10928 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2019-06-25 18:24:51.271  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2019-06-25 18:24:51.380  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2019-06-25 18:24:51.380  INFO 10928 --- [ExpirationReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2019-06-25 18:24:51.380  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2019-06-25 18:24:51.552  INFO 10928 --- [ExpirationReaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2019-06-25 18:24:51.552  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2019-06-25 18:24:51.552  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2019-06-25 18:24:51.693  INFO 10928 --- [ExpirationReaper-0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2019-06-25 18:24:51.693  INFO 10928 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2019-06-25 18:24:51.726  INFO 10928 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2019-06-25 18:24:51.741  INFO 10928 --- [main] kafka.log.LogManager                     : Shutting down.
2019-06-25 18:24:51.741  INFO 10928 --- [main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2019-06-25 18:24:51.741  INFO 10928 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2019-06-25 18:24:51.741  INFO 10928 --- [kafka-log-cleaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2019-06-25 18:24:51.741  INFO 10928 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2019-06-25 18:24:51.835  INFO 10928 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=helloworld.t-0] Writing producer snapshot at offset 1
2019-06-25 18:24:51.850  INFO 10928 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 4
2019-06-25 18:24:51.882  INFO 10928 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 4
2019-06-25 18:24:52.022  INFO 10928 --- [main] kafka.log.LogManager                     : Shutdown complete.
2019-06-25 18:24:52.022  INFO 10928 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2019-06-25 18:24:52.022  INFO 10928 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2019-06-25 18:24:52.022  INFO 10928 --- [main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2019-06-25 18:24:52.022  INFO 10928 --- [main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=0] Stopped partition state machine
2019-06-25 18:24:52.022  INFO 10928 --- [main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2019-06-25 18:24:52.022  INFO 10928 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2019-06-25 18:24:52.022  INFO 10928 --- [Controller-0-to-broker-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2019-06-25 18:24:52.022  INFO 10928 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2019-06-25 18:24:52.038  INFO 10928 --- [main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2019-06-25 18:24:52.038  INFO 10928 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2019-06-25 18:24:52.038  INFO 10928 --- [ProcessThread(sid:0 cport:61448):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x1000082308d0001
2019-06-25 18:24:52.054  INFO 10928 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x1000082308d0001 closed
2019-06-25 18:24:52.054  INFO 10928 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1000082308d0001
2019-06-25 18:24:52.054  INFO 10928 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61454 which had sessionid 0x1000082308d0001
2019-06-25 18:24:52.069  INFO 10928 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2019-06-25 18:24:52.069  INFO 10928 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2019-06-25 18:24:52.913  INFO 10928 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2019-06-25 18:24:52.913  INFO 10928 --- [ThrottledChannelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2019-06-25 18:24:52.914  INFO 10928 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2019-06-25 18:24:53.884  INFO 10928 --- [ThrottledChannelReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2019-06-25 18:24:53.884  INFO 10928 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2019-06-25 18:24:53.884  INFO 10928 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2019-06-25 18:24:53.915  INFO 10928 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2019-06-25 18:24:53.915  INFO 10928 --- [ThrottledChannelReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2019-06-25 18:24:53.917  INFO 10928 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutting down socket server
2019-06-25 18:24:53.932  INFO 10928 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutdown completed
2019-06-25 18:24:53.932  INFO 10928 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2019-06-25 18:24:53.948  INFO 10928 --- [ZkClient-EventThread-20-127.0.0.1:61448] org.I0Itec.zkclient.ZkEventThread        : Terminate ZkClient event thread.
2019-06-25 18:24:53.948  INFO 10928 --- [ProcessThread(sid:0 cport:61448):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x1000082308d0000
2019-06-25 18:24:53.964  INFO 10928 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x1000082308d0000 closed
2019-06-25 18:24:53.964  INFO 10928 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1000082308d0000
2019-06-25 18:24:53.964  INFO 10928 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61451 which had sessionid 0x1000082308d0000
2019-06-25 18:24:53.964  INFO 10928 --- [main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2019-06-25 18:24:53.964  INFO 10928 --- [main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2019-06-25 18:24:53.964  INFO 10928 --- [main] o.a.z.server.PrepRequestProcessor        : Shutting down
2019-06-25 18:24:53.964  INFO 10928 --- [main] o.a.z.server.SyncRequestProcessor        : Shutting down
2019-06-25 18:24:53.964  INFO 10928 --- [ProcessThread(sid:0 cport:61448):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2019-06-25 18:24:53.964  INFO 10928 --- [SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2019-06-25 18:24:53.964  INFO 10928 --- [main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2019-06-25 18:24:53.979  INFO 10928 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2019-06-25 18:24:54.433  INFO 10928 --- [SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2019-06-25 18:24:54.995 ERROR 10928 --- [Thread-3] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-13082855323555743174\helloworld.t-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:24:55.004 ERROR 10928 --- [Thread-0] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-9662201833699747784

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-9662201833699747784\version-2\log.1: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:29:42.758  INFO 9856 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Starting SpringKafkaApplicationTest on DIN69001166 with PID 9856 (started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 18:29:42.759  INFO 9856 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : No active profile set, falling back to default profiles: default
2019-06-25 18:29:43.564  INFO 9856 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 18:29:43.656  INFO 9856 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 85ms. Found 3 repository interfaces.
2019-06-25 18:29:44.057  INFO 9856 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$6267d5d1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:29:44.177  INFO 9856 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$334d894d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:29:44.236  INFO 9856 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 18:29:44.272  INFO 9856 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$8eb5c44e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:29:44.528  INFO 9856 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 18:29:44.532  WARN 9856 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 18:29:44.797  INFO 9856 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 18:29:44.799  INFO 9856 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 18:29:44.879  INFO 9856 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 18:29:44.952  INFO 9856 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 18:29:44.957  INFO 9856 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 18:29:45.114  INFO 9856 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 18:29:45.260  INFO 9856 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 18:29:45.965  WARN 9856 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) ~[junit-4.12.jar:4.12]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) ~[.cp/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 61 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 66 common frames omitted

2019-06-25 18:29:45.975  INFO 9856 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@67e37d25'
2019-06-25 18:29:45.978  INFO 9856 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:29:46.421  INFO 9856 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 18:29:47.663  INFO 9856 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 18:29:47.753  WARN 9856 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 18:29:48.579  INFO 9856 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61526]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:29:48.617  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:29:48.618  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:29:48.630  INFO 9856 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: 8qloHBzuTg2Fv1ovCKnibQ
2019-06-25 18:29:48.646  INFO 9856 --- [ProcessThread(sid:0 cport:61517):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1000086e4390001 type:setData cxid:0x50 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/helloworld.t Error:KeeperErrorCode = NoNode for /config/topics/helloworld.t
2019-06-25 18:29:48.720  INFO 9856 --- [kafka-request-handler-6] kafka.zk.AdminZkClient                   : Topic creation Map(helloworld.t-0 -> ArrayBuffer(0))
2019-06-25 18:29:48.751  INFO 9856 --- [kafka-request-handler-6] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic helloworld.t with 1 partitions and replication factor 1 is successful
2019-06-25 18:29:48.752  INFO 9856 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(helloworld.t)], deleted topics: [Set()], new partition replica assignment [Map(helloworld.t-0 -> Vector(0))]
2019-06-25 18:29:48.752  INFO 9856 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for helloworld.t-0
2019-06-25 18:29:48.818  INFO 9856 --- [kafka-request-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions helloworld.t-0
2019-06-25 18:29:48.830  INFO 9856 --- [kafka-request-handler-1] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Loading producer state till offset 0 with message format version 2
2019-06-25 18:29:48.833  INFO 9856 --- [kafka-request-handler-1] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms
2019-06-25 18:29:48.834  INFO 9856 --- [kafka-request-handler-1] kafka.log.LogManager                     : Created log for partition helloworld.t-0 in C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:29:48.834  INFO 9856 --- [kafka-request-handler-1] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] No checkpointed highwatermark is found for partition helloworld.t-0
2019-06-25 18:29:48.835  INFO 9856 --- [kafka-request-handler-1] kafka.cluster.Replica                    : Replica loaded for partition helloworld.t-0 with initial high watermark 0
2019-06-25 18:29:48.835  INFO 9856 --- [kafka-request-handler-1] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] helloworld.t-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:29:48.885  INFO 9856 --- [kafka-request-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:29:48.996  INFO 9856 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61526]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:29:49.002  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:29:49.002  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:29:49.005  INFO 9856 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:29:49.019  INFO 9856 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Started SpringKafkaApplicationTest in 6.562 seconds (JVM running for 12.037)
2019-06-25 18:29:49.024  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: 8qloHBzuTg2Fv1ovCKnibQ
2019-06-25 18:29:49.038  INFO 9856 --- [ProcessThread(sid:0 cport:61517):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x1000086e4390001 type:setData cxid:0x60 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-06-25 18:29:49.122  INFO 9856 --- [kafka-request-handler-4] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-06-25 18:29:49.163  INFO 9856 --- [kafka-request-handler-4] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-06-25 18:29:49.175  INFO 9856 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-06-25 18:29:49.175  INFO 9856 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:29:49.267  INFO 9856 --- [kafka-request-handler-7] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:29:49.297  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Loading producer state till offset 0 with message format version 2
2019-06-25 18:29:49.300  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms
2019-06-25 18:29:49.301  INFO 9856 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:29:49.302  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-06-25 18:29:49.303  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-06-25 18:29:49.303  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:29:49.345  INFO 9856 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61526]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:29:49.353  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:29:49.353  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:29:49.364  INFO 9856 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: 8qloHBzuTg2Fv1ovCKnibQ
2019-06-25 18:29:49.370  INFO 9856 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61526]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:29:49.375  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:29:49.375  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:29:49.375  INFO 9856 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:29:49.460  INFO 9856 --- [-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: 8qloHBzuTg2Fv1ovCKnibQ
2019-06-25 18:29:49.470  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Loading producer state till offset 0 with message format version 2
2019-06-25 18:29:49.474  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms
2019-06-25 18:29:49.475  INFO 9856 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:29:49.475  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-06-25 18:29:49.475  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-06-25 18:29:49.475  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:29:49.554  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Loading producer state till offset 0 with message format version 2
2019-06-25 18:29:49.556  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms
2019-06-25 18:29:49.557  INFO 9856 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:29:49.558  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-06-25 18:29:49.558  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-06-25 18:29:49.558  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:29:49.630  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Loading producer state till offset 0 with message format version 2
2019-06-25 18:29:49.633  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2019-06-25 18:29:49.633  INFO 9856 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:29:49.634  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-06-25 18:29:49.634  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-06-25 18:29:49.634  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:29:49.775  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Loading producer state till offset 0 with message format version 2
2019-06-25 18:29:49.784  INFO 9856 --- [kafka-request-handler-7] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms
2019-06-25 18:29:49.786  INFO 9856 --- [kafka-request-handler-7] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:29:49.788  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-06-25 18:29:49.788  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-06-25 18:29:49.789  INFO 9856 --- [kafka-request-handler-7] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:29:49.843  INFO 9856 --- [kafka-request-handler-7] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:29:49.847  INFO 9856 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-06-25 18:29:49.849  INFO 9856 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-06-25 18:29:49.849  INFO 9856 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-06-25 18:29:49.849  INFO 9856 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-06-25 18:29:49.850  INFO 9856 --- [kafka-request-handler-7] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-06-25 18:29:49.871  INFO 9856 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 22 milliseconds.
2019-06-25 18:29:49.873  INFO 9856 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds.
2019-06-25 18:29:49.874  INFO 9856 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds.
2019-06-25 18:29:49.874  INFO 9856 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-06-25 18:29:49.875  INFO 9856 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2019-06-25 18:29:49.884  INFO 9856 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Discovered group coordinator localhost:61526 (id: 2147483647 rack: null)
2019-06-25 18:29:49.890  INFO 9856 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Revoking previously assigned partitions []
2019-06-25 18:29:49.890  INFO 9856 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:29:49.891  INFO 9856 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] (Re-)joining group
2019-06-25 18:29:49.900  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Discovered group coordinator localhost:61526 (id: 2147483647 rack: null)
2019-06-25 18:29:49.902  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Revoking previously assigned partitions []
2019-06-25 18:29:49.902  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:29:49.902  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] (Re-)joining group
2019-06-25 18:29:49.913  INFO 9856 --- [kafka-request-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 0 (__consumer_offsets-2)
2019-06-25 18:29:49.913  INFO 9856 --- [kafka-request-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 0 (__consumer_offsets-0)
2019-06-25 18:29:49.921  INFO 9856 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group helloworld generation 1 (__consumer_offsets-2)
2019-06-25 18:29:49.926  INFO 9856 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group sender generation 1 (__consumer_offsets-0)
2019-06-25 18:29:49.929  INFO 9856 --- [kafka-request-handler-2] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group sender for generation 1
2019-06-25 18:29:49.929  INFO 9856 --- [kafka-request-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group helloworld for generation 1
2019-06-25 18:29:49.973  INFO 9856 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Successfully joined group with generation 1
2019-06-25 18:29:49.973  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Successfully joined group with generation 1
2019-06-25 18:29:49.975  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Setting newly assigned partitions [helloworld.t-0]
2019-06-25 18:29:49.975  INFO 9856 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Setting newly assigned partitions [sender.t-1, sender.t-0]
2019-06-25 18:29:49.989  INFO 9856 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-1 to offset 0.
2019-06-25 18:29:49.989  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:29:49.989  INFO 9856 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-0 to offset 0.
2019-06-25 18:29:49.990  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0]
2019-06-25 18:29:50.000  INFO 9856 --- [main] com.cg.Lib.producer.Sender               : sending payload='Hello Spring Kafka Sender!'
2019-06-25 18:29:50.002  INFO 9856 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [sender.t-1, sender.t-0]
2019-06-25 18:29:50.006  INFO 9856 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:61526]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-25 18:29:50.021  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:29:50.021  INFO 9856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:29:50.027  INFO 9856 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: 8qloHBzuTg2Fv1ovCKnibQ
2019-06-25 18:29:50.068  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.cg.Lib.consumer.Receiver             : received payload='Hello Spring Kafka Sender!'
2019-06-25 18:32:42.547  INFO 9856 --- [-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:32:42.550  INFO 9856 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 1 (__consumer_offsets-0)
2019-06-25 18:32:42.551  INFO 9856 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group sender with generation 2 is now empty (__consumer_offsets-0)
2019-06-25 18:32:42.560  INFO 9856 --- [-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:32:42.580  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:32:42.581  INFO 9856 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 1 (__consumer_offsets-2)
2019-06-25 18:32:42.582  INFO 9856 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group helloworld with generation 2 is now empty (__consumer_offsets-2)
2019-06-25 18:32:42.586  INFO 9856 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:32:42.588  INFO 9856 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-06-25 18:32:42.590  INFO 9856 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-06-25 18:32:42.594  INFO 9856 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:32:42.597  INFO 9856 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 18:32:42.603  INFO 9856 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 18:32:42.607  INFO 9856 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2019-06-25 18:32:42.608  INFO 9856 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Starting controlled shutdown
2019-06-25 18:32:42.623  INFO 9856 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] Shutting down broker 0
2019-06-25 18:32:42.630  INFO 9856 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Controlled shutdown succeeded
2019-06-25 18:32:42.632  INFO 9856 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2019-06-25 18:32:42.633  INFO 9856 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2019-06-25 18:32:42.633  INFO 9856 --- [/config/changes-event-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2019-06-25 18:32:42.634  INFO 9856 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopping socket server request processors
2019-06-25 18:32:42.650  INFO 9856 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopped socket server request processors
2019-06-25 18:32:42.651  INFO 9856 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shutting down
2019-06-25 18:32:42.657  INFO 9856 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shut down completely
2019-06-25 18:32:42.662  INFO 9856 --- [main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2019-06-25 18:32:42.664  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2019-06-25 18:32:42.801  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2019-06-25 18:32:42.803  INFO 9856 --- [ExpirationReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2019-06-25 18:32:42.804  INFO 9856 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2019-06-25 18:32:42.806  INFO 9856 --- [main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2019-06-25 18:32:42.807  INFO 9856 --- [main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2019-06-25 18:32:42.807  INFO 9856 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutting down
2019-06-25 18:32:42.807  INFO 9856 --- [TxnMarkerSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Stopped
2019-06-25 18:32:42.807  INFO 9856 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutdown completed
2019-06-25 18:32:42.808  INFO 9856 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2019-06-25 18:32:42.809  INFO 9856 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2019-06-25 18:32:42.809  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2019-06-25 18:32:42.874  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2019-06-25 18:32:42.874  INFO 9856 --- [ExpirationReaper-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2019-06-25 18:32:42.874  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2019-06-25 18:32:42.983  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2019-06-25 18:32:42.983  INFO 9856 --- [ExpirationReaper-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2019-06-25 18:32:42.984  INFO 9856 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2019-06-25 18:32:42.985  INFO 9856 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2019-06-25 18:32:42.986  INFO 9856 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2019-06-25 18:32:42.986  INFO 9856 --- [LogDirFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2019-06-25 18:32:42.986  INFO 9856 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2019-06-25 18:32:42.987  INFO 9856 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2019-06-25 18:32:42.989  INFO 9856 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2019-06-25 18:32:42.989  INFO 9856 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutting down
2019-06-25 18:32:42.990  INFO 9856 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2019-06-25 18:32:42.990  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2019-06-25 18:32:43.061  INFO 9856 --- [ExpirationReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2019-06-25 18:32:43.061  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2019-06-25 18:32:43.061  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2019-06-25 18:32:43.165  INFO 9856 --- [ExpirationReaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2019-06-25 18:32:43.165  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2019-06-25 18:32:43.165  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2019-06-25 18:32:43.184  INFO 9856 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2019-06-25 18:32:43.184  INFO 9856 --- [ExpirationReaper-0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2019-06-25 18:32:43.231  INFO 9856 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2019-06-25 18:32:43.232  INFO 9856 --- [main] kafka.log.LogManager                     : Shutting down.
2019-06-25 18:32:43.233  INFO 9856 --- [main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2019-06-25 18:32:43.233  INFO 9856 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2019-06-25 18:32:43.234  INFO 9856 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2019-06-25 18:32:43.234  INFO 9856 --- [kafka-log-cleaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2019-06-25 18:32:43.314  INFO 9856 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=helloworld.t-0] Writing producer snapshot at offset 1
2019-06-25 18:32:43.384  INFO 9856 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 36
2019-06-25 18:32:43.421  INFO 9856 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 4
2019-06-25 18:32:43.608  INFO 9856 --- [main] kafka.log.LogManager                     : Shutdown complete.
2019-06-25 18:32:43.610  INFO 9856 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2019-06-25 18:32:43.610  INFO 9856 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2019-06-25 18:32:43.610  INFO 9856 --- [main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2019-06-25 18:32:43.615  INFO 9856 --- [main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=0] Stopped partition state machine
2019-06-25 18:32:43.618  INFO 9856 --- [main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2019-06-25 18:32:43.618  INFO 9856 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2019-06-25 18:32:43.619  INFO 9856 --- [Controller-0-to-broker-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2019-06-25 18:32:43.619  INFO 9856 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2019-06-25 18:32:43.622  INFO 9856 --- [main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2019-06-25 18:32:43.626  INFO 9856 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2019-06-25 18:32:43.627  INFO 9856 --- [ProcessThread(sid:0 cport:61517):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x1000086e4390001
2019-06-25 18:32:43.646  INFO 9856 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x1000086e4390001 closed
2019-06-25 18:32:43.646  INFO 9856 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1000086e4390001
2019-06-25 18:32:43.646  WARN 9856 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Unable to read additional data from client sessionid 0x1000086e4390001, likely client has closed socket
2019-06-25 18:32:43.648  INFO 9856 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61523 which had sessionid 0x1000086e4390001
2019-06-25 18:32:43.648  INFO 9856 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2019-06-25 18:32:43.649  INFO 9856 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2019-06-25 18:32:44.191  INFO 9856 --- [ThrottledChannelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2019-06-25 18:32:44.191  INFO 9856 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2019-06-25 18:32:44.191  INFO 9856 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2019-06-25 18:32:45.190  INFO 9856 --- [ThrottledChannelReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2019-06-25 18:32:45.190  INFO 9856 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2019-06-25 18:32:45.190  INFO 9856 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2019-06-25 18:32:46.188  INFO 9856 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2019-06-25 18:32:46.188  INFO 9856 --- [ThrottledChannelReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2019-06-25 18:32:46.192  INFO 9856 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutting down socket server
2019-06-25 18:32:46.238  INFO 9856 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutdown completed
2019-06-25 18:32:46.243  INFO 9856 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2019-06-25 18:32:46.250  INFO 9856 --- [ZkClient-EventThread-23-127.0.0.1:61517] org.I0Itec.zkclient.ZkEventThread        : Terminate ZkClient event thread.
2019-06-25 18:32:46.251  INFO 9856 --- [ProcessThread(sid:0 cport:61517):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x1000086e4390000
2019-06-25 18:32:46.274  INFO 9856 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x1000086e4390000
2019-06-25 18:32:46.274  INFO 9856 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x1000086e4390000 closed
2019-06-25 18:32:46.275  INFO 9856 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61520 which had sessionid 0x1000086e4390000
2019-06-25 18:32:46.276  INFO 9856 --- [main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2019-06-25 18:32:46.276  INFO 9856 --- [main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2019-06-25 18:32:46.276  INFO 9856 --- [main] o.a.z.server.PrepRequestProcessor        : Shutting down
2019-06-25 18:32:46.276  INFO 9856 --- [main] o.a.z.server.SyncRequestProcessor        : Shutting down
2019-06-25 18:32:46.276  INFO 9856 --- [ProcessThread(sid:0 cport:61517):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2019-06-25 18:32:46.276  INFO 9856 --- [SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2019-06-25 18:32:46.277  INFO 9856 --- [main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2019-06-25 18:32:46.284  INFO 9856 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2019-06-25 18:32:46.432  INFO 9856 --- [SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2019-06-25 18:32:47.319 ERROR 9856 --- [Thread-3] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-10547723867116332337\helloworld.t-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:32:47.320 ERROR 9856 --- [Thread-0] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-3839953501703893461

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-3839953501703893461\version-2\log.1: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:33:30.183  INFO 6992 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Starting SpringKafkaApplicationTest on DIN69001166 with PID 6992 (started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 18:33:30.185  INFO 6992 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : No active profile set, falling back to default profiles: default
2019-06-25 18:33:31.006  INFO 6992 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 18:33:31.125  INFO 6992 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 111ms. Found 3 repository interfaces.
2019-06-25 18:33:31.539  INFO 6992 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$ca556e8b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:33:31.666  INFO 6992 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$9b3b2207] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:33:31.713  INFO 6992 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 18:33:31.749  INFO 6992 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$f6a35d08] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:33:32.028  INFO 6992 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 18:33:32.033  WARN 6992 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 18:33:32.294  INFO 6992 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 18:33:32.297  INFO 6992 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 18:33:32.394  INFO 6992 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 18:33:32.468  INFO 6992 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 18:33:32.471  INFO 6992 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 18:33:32.616  INFO 6992 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 18:33:32.772  INFO 6992 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 18:33:33.468  WARN 6992 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) ~[junit-4.12.jar:4.12]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) ~[.cp/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 61 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 66 common frames omitted

2019-06-25 18:33:33.479  INFO 6992 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@62818ab0'
2019-06-25 18:33:33.482  INFO 6992 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:33:33.886  INFO 6992 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 18:33:35.078  INFO 6992 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 18:33:35.151  WARN 6992 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 18:33:35.849  INFO 6992 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61592]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:33:35.910  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:33:35.910  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:33:35.920  INFO 6992 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: k558WqUZQqKInK02wbjNHA
2019-06-25 18:33:35.933  INFO 6992 --- [ProcessThread(sid:0 cport:61583):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100008a5b090001 type:setData cxid:0x50 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/helloworld.t Error:KeeperErrorCode = NoNode for /config/topics/helloworld.t
2019-06-25 18:33:35.994  INFO 6992 --- [kafka-request-handler-1] kafka.zk.AdminZkClient                   : Topic creation Map(helloworld.t-0 -> ArrayBuffer(0))
2019-06-25 18:33:36.018  INFO 6992 --- [kafka-request-handler-1] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic helloworld.t with 1 partitions and replication factor 1 is successful
2019-06-25 18:33:36.021  INFO 6992 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(helloworld.t)], deleted topics: [Set()], new partition replica assignment [Map(helloworld.t-0 -> Vector(0))]
2019-06-25 18:33:36.021  INFO 6992 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for helloworld.t-0
2019-06-25 18:33:36.223  INFO 6992 --- [kafka-request-handler-1] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions helloworld.t-0
2019-06-25 18:33:36.252  INFO 6992 --- [kafka-request-handler-1] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Loading producer state till offset 0 with message format version 2
2019-06-25 18:33:36.254  INFO 6992 --- [kafka-request-handler-1] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2019-06-25 18:33:36.256  INFO 6992 --- [kafka-request-handler-1] kafka.log.LogManager                     : Created log for partition helloworld.t-0 in C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:33:36.257  INFO 6992 --- [kafka-request-handler-1] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] No checkpointed highwatermark is found for partition helloworld.t-0
2019-06-25 18:33:36.257  INFO 6992 --- [kafka-request-handler-1] kafka.cluster.Replica                    : Replica loaded for partition helloworld.t-0 with initial high watermark 0
2019-06-25 18:33:36.257  INFO 6992 --- [kafka-request-handler-1] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] helloworld.t-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:33:36.388  INFO 6992 --- [kafka-request-handler-1] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:33:36.448  INFO 6992 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61592]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:33:36.453  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:33:36.453  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:33:36.456  INFO 6992 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:33:36.470  INFO 6992 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Started SpringKafkaApplicationTest in 6.589 seconds (JVM running for 11.875)
2019-06-25 18:33:36.487  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: k558WqUZQqKInK02wbjNHA
2019-06-25 18:33:36.499  INFO 6992 --- [ProcessThread(sid:0 cport:61583):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100008a5b090001 type:setData cxid:0x63 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-06-25 18:33:36.558  INFO 6992 --- [kafka-request-handler-4] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-06-25 18:33:36.580  INFO 6992 --- [kafka-request-handler-4] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-06-25 18:33:36.619  INFO 6992 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-06-25 18:33:36.619  INFO 6992 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:33:36.797  INFO 6992 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61592]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:33:36.804  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:33:36.806  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:33:36.813  INFO 6992 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: k558WqUZQqKInK02wbjNHA
2019-06-25 18:33:36.817  INFO 6992 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61592]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:33:36.821  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:33:36.822  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:33:36.822  INFO 6992 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:33:36.851  INFO 6992 --- [kafka-request-handler-2] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:33:36.926  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Loading producer state till offset 0 with message format version 2
2019-06-25 18:33:36.929  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms
2019-06-25 18:33:36.932  INFO 6992 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:33:36.939  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-06-25 18:33:36.939  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-06-25 18:33:36.940  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:33:36.947  INFO 6992 --- [-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: k558WqUZQqKInK02wbjNHA
2019-06-25 18:33:37.011  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Loading producer state till offset 0 with message format version 2
2019-06-25 18:33:37.014  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms
2019-06-25 18:33:37.015  INFO 6992 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:33:37.016  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-06-25 18:33:37.016  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-06-25 18:33:37.017  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:33:37.101  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Loading producer state till offset 0 with message format version 2
2019-06-25 18:33:37.104  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2019-06-25 18:33:37.105  INFO 6992 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:33:37.106  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-06-25 18:33:37.106  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-06-25 18:33:37.106  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:33:37.313  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Loading producer state till offset 0 with message format version 2
2019-06-25 18:33:37.320  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms
2019-06-25 18:33:37.322  INFO 6992 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:33:37.323  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-06-25 18:33:37.324  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-06-25 18:33:37.324  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:33:37.434  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Loading producer state till offset 0 with message format version 2
2019-06-25 18:33:37.446  INFO 6992 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms
2019-06-25 18:33:37.448  INFO 6992 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in C:\Users\agunture\AppData\Local\Temp\kafka-5304223790246353924 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:33:37.449  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-06-25 18:33:37.449  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-06-25 18:33:37.449  INFO 6992 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:33:37.568  INFO 6992 --- [kafka-request-handler-2] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:33:37.572  INFO 6992 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-06-25 18:33:37.574  INFO 6992 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-06-25 18:33:37.574  INFO 6992 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-06-25 18:33:37.574  INFO 6992 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-06-25 18:33:37.575  INFO 6992 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-06-25 18:33:37.591  INFO 6992 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 17 milliseconds.
2019-06-25 18:33:37.592  INFO 6992 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2019-06-25 18:33:37.592  INFO 6992 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2019-06-25 18:33:37.592  INFO 6992 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-06-25 18:33:37.592  INFO 6992 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2019-06-25 18:33:37.645  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Discovered group coordinator localhost:61592 (id: 2147483647 rack: null)
2019-06-25 18:33:37.649  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Revoking previously assigned partitions []
2019-06-25 18:33:37.650  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:33:37.650  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] (Re-)joining group
2019-06-25 18:33:37.665  INFO 6992 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Discovered group coordinator localhost:61592 (id: 2147483647 rack: null)
2019-06-25 18:33:37.667  INFO 6992 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Revoking previously assigned partitions []
2019-06-25 18:33:37.667  INFO 6992 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:33:37.667  INFO 6992 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] (Re-)joining group
2019-06-25 18:33:37.680  INFO 6992 --- [kafka-request-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 0 (__consumer_offsets-2)
2019-06-25 18:33:37.680  INFO 6992 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 0 (__consumer_offsets-0)
2019-06-25 18:33:37.692  INFO 6992 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group sender generation 1 (__consumer_offsets-0)
2019-06-25 18:33:37.701  INFO 6992 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group helloworld generation 1 (__consumer_offsets-2)
2019-06-25 18:33:37.706  INFO 6992 --- [kafka-request-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group sender for generation 1
2019-06-25 18:33:37.706  INFO 6992 --- [kafka-request-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group helloworld for generation 1
2019-06-25 18:33:37.761  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Successfully joined group with generation 1
2019-06-25 18:33:37.761  INFO 6992 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Successfully joined group with generation 1
2019-06-25 18:33:37.763  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Setting newly assigned partitions [helloworld.t-0]
2019-06-25 18:33:37.763  INFO 6992 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Setting newly assigned partitions [sender.t-1, sender.t-0]
2019-06-25 18:33:37.775  INFO 6992 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-1 to offset 0.
2019-06-25 18:33:37.775  INFO 6992 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-0 to offset 0.
2019-06-25 18:33:37.775  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:33:37.777  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0]
2019-06-25 18:33:37.790  INFO 6992 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [sender.t-1, sender.t-0]
2019-06-25 18:33:37.822  INFO 6992 --- [main] com.cg.Lib.producer.Sender               : sending payload='Hello Spring Kafka Sender!'
2019-06-25 18:33:37.827  INFO 6992 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:61592]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-25 18:33:37.844  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:33:37.845  INFO 6992 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:33:37.852  INFO 6992 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: k558WqUZQqKInK02wbjNHA
2019-06-25 18:33:37.916  INFO 6992 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.cg.Lib.consumer.Receiver             : received payload='Hello Spring Kafka Sender!'
2019-06-25 18:35:27.380  INFO 2756 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Starting SpringKafkaApplicationTest on DIN69001166 with PID 2756 (started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 18:35:27.381  INFO 2756 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : No active profile set, falling back to default profiles: default
2019-06-25 18:35:28.440  INFO 2756 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 18:35:28.541  INFO 2756 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 95ms. Found 3 repository interfaces.
2019-06-25 18:35:28.947  INFO 2756 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$12c28f0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:35:29.083  INFO 2756 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$d211dc6c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:35:29.132  INFO 2756 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 18:35:29.167  INFO 2756 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$2d7a176d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:35:29.431  INFO 2756 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 18:35:29.435  WARN 2756 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 18:35:29.657  INFO 2756 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 18:35:29.660  INFO 2756 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 18:35:29.755  INFO 2756 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 18:35:29.825  INFO 2756 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 18:35:29.827  INFO 2756 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 18:35:29.969  INFO 2756 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 18:35:30.125  INFO 2756 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 18:35:30.817  WARN 2756 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) ~[junit-4.12.jar:4.12]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) ~[.cp/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 61 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 66 common frames omitted

2019-06-25 18:35:30.826  INFO 2756 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@14aa2123'
2019-06-25 18:35:30.828  INFO 2756 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:35:31.248  INFO 2756 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 18:35:32.316  INFO 2756 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 18:35:32.382  WARN 2756 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 18:35:33.057  INFO 2756 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61651]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:35:33.098  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:35:33.098  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:35:33.107  INFO 2756 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: uXb6ma9eTZyd3sJRYFveWQ
2019-06-25 18:35:33.117  INFO 2756 --- [ProcessThread(sid:0 cport:61641):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100008c257d0001 type:setData cxid:0x50 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/helloworld.t Error:KeeperErrorCode = NoNode for /config/topics/helloworld.t
2019-06-25 18:35:33.183  INFO 2756 --- [kafka-request-handler-5] kafka.zk.AdminZkClient                   : Topic creation Map(helloworld.t-0 -> ArrayBuffer(0))
2019-06-25 18:35:33.216  INFO 2756 --- [kafka-request-handler-5] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic helloworld.t with 1 partitions and replication factor 1 is successful
2019-06-25 18:35:33.218  INFO 2756 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(helloworld.t)], deleted topics: [Set()], new partition replica assignment [Map(helloworld.t-0 -> Vector(0))]
2019-06-25 18:35:33.218  INFO 2756 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for helloworld.t-0
2019-06-25 18:35:33.282  INFO 2756 --- [kafka-request-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions helloworld.t-0
2019-06-25 18:35:33.335  INFO 2756 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Loading producer state till offset 0 with message format version 2
2019-06-25 18:35:33.337  INFO 2756 --- [kafka-request-handler-3] kafka.log.Log                            : [Log partition=helloworld.t-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms
2019-06-25 18:35:33.338  INFO 2756 --- [kafka-request-handler-3] kafka.log.LogManager                     : Created log for partition helloworld.t-0 in C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:35:33.339  INFO 2756 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] No checkpointed highwatermark is found for partition helloworld.t-0
2019-06-25 18:35:33.339  INFO 2756 --- [kafka-request-handler-3] kafka.cluster.Replica                    : Replica loaded for partition helloworld.t-0 with initial high watermark 0
2019-06-25 18:35:33.339  INFO 2756 --- [kafka-request-handler-3] kafka.cluster.Partition                  : [Partition helloworld.t-0 broker=0] helloworld.t-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:35:33.400  INFO 2756 --- [kafka-request-handler-3] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:35:33.465  INFO 2756 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61651]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:35:33.471  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:35:33.471  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:35:33.474  INFO 2756 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:35:33.491  INFO 2756 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Started SpringKafkaApplicationTest in 6.424 seconds (JVM running for 11.505)
2019-06-25 18:35:33.497  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: uXb6ma9eTZyd3sJRYFveWQ
2019-06-25 18:35:33.512  INFO 2756 --- [ProcessThread(sid:0 cport:61641):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100008c257d0001 type:setData cxid:0x60 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-06-25 18:35:33.656  INFO 2756 --- [kafka-request-handler-7] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-06-25 18:35:33.680  INFO 2756 --- [kafka-request-handler-7] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-06-25 18:35:33.715  INFO 2756 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-06-25 18:35:33.715  INFO 2756 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:35:33.833  INFO 2756 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61651]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:35:33.842  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:35:33.843  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:35:33.852  INFO 2756 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: uXb6ma9eTZyd3sJRYFveWQ
2019-06-25 18:35:33.857  INFO 2756 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61651]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:35:33.862  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:35:33.862  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:35:33.862  INFO 2756 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:35:33.869  INFO 2756 --- [kafka-request-handler-2] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:35:33.908  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Loading producer state till offset 0 with message format version 2
2019-06-25 18:35:33.910  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms
2019-06-25 18:35:33.917  INFO 2756 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:35:33.918  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-06-25 18:35:33.918  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-06-25 18:35:33.918  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:35:33.962  INFO 2756 --- [-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: uXb6ma9eTZyd3sJRYFveWQ
2019-06-25 18:35:34.021  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Loading producer state till offset 0 with message format version 2
2019-06-25 18:35:34.027  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms
2019-06-25 18:35:34.030  INFO 2756 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:35:34.032  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-06-25 18:35:34.032  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-06-25 18:35:34.032  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:35:34.134  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Loading producer state till offset 0 with message format version 2
2019-06-25 18:35:34.137  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms
2019-06-25 18:35:34.138  INFO 2756 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:35:34.138  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-06-25 18:35:34.139  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-06-25 18:35:34.139  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:35:34.230  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Loading producer state till offset 0 with message format version 2
2019-06-25 18:35:34.242  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms
2019-06-25 18:35:34.245  INFO 2756 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:35:34.248  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-06-25 18:35:34.249  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-06-25 18:35:34.249  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:35:34.352  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Loading producer state till offset 0 with message format version 2
2019-06-25 18:35:34.360  INFO 2756 --- [kafka-request-handler-2] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms
2019-06-25 18:35:34.362  INFO 2756 --- [kafka-request-handler-2] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:35:34.364  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-06-25 18:35:34.364  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-06-25 18:35:34.365  INFO 2756 --- [kafka-request-handler-2] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:35:34.418  INFO 2756 --- [kafka-request-handler-2] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:35:34.423  INFO 2756 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-06-25 18:35:34.425  INFO 2756 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-06-25 18:35:34.425  INFO 2756 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-06-25 18:35:34.425  INFO 2756 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-06-25 18:35:34.426  INFO 2756 --- [kafka-request-handler-2] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-06-25 18:35:34.446  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Discovered group coordinator localhost:61651 (id: 2147483647 rack: null)
2019-06-25 18:35:34.448  INFO 2756 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 23 milliseconds.
2019-06-25 18:35:34.449  INFO 2756 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2019-06-25 18:35:34.449  INFO 2756 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2019-06-25 18:35:34.450  INFO 2756 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-06-25 18:35:34.450  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Revoking previously assigned partitions []
2019-06-25 18:35:34.451  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:35:34.451  INFO 2756 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds.
2019-06-25 18:35:34.451  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] (Re-)joining group
2019-06-25 18:35:34.470  INFO 2756 --- [kafka-request-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 0 (__consumer_offsets-2)
2019-06-25 18:35:34.481  INFO 2756 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Discovered group coordinator localhost:61651 (id: 2147483647 rack: null)
2019-06-25 18:35:34.482  INFO 2756 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group helloworld generation 1 (__consumer_offsets-2)
2019-06-25 18:35:34.482  INFO 2756 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Revoking previously assigned partitions []
2019-06-25 18:35:34.483  INFO 2756 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:35:34.483  INFO 2756 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] (Re-)joining group
2019-06-25 18:35:34.485  INFO 2756 --- [kafka-request-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 0 (__consumer_offsets-0)
2019-06-25 18:35:34.495  INFO 2756 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group sender generation 1 (__consumer_offsets-0)
2019-06-25 18:35:34.497  INFO 2756 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group helloworld for generation 1
2019-06-25 18:35:34.497  INFO 2756 --- [kafka-request-handler-4] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group sender for generation 1
2019-06-25 18:35:34.543  INFO 2756 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Successfully joined group with generation 1
2019-06-25 18:35:34.543  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Successfully joined group with generation 1
2019-06-25 18:35:34.545  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Setting newly assigned partitions [helloworld.t-0]
2019-06-25 18:35:34.545  INFO 2756 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Setting newly assigned partitions [sender.t-1, sender.t-0]
2019-06-25 18:35:34.557  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:35:34.557  INFO 2756 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-1 to offset 0.
2019-06-25 18:35:34.557  INFO 2756 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition sender.t-0 to offset 0.
2019-06-25 18:35:34.558  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0]
2019-06-25 18:35:34.570  INFO 2756 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [sender.t-1, sender.t-0]
2019-06-25 18:37:20.680  INFO 2756 --- [main] com.cg.Lib.producer.Sender               : sending payload='Hello Spring Kafka Sender!'
2019-06-25 18:37:20.896  INFO 2756 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:61651]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-25 18:37:21.657  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:37:21.664  INFO 2756 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:37:21.729  INFO 2756 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: uXb6ma9eTZyd3sJRYFveWQ
2019-06-25 18:37:21.998  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.cg.Lib.consumer.Receiver             : received payload='Hello Spring Kafka Sender!'
2019-06-25 18:40:03.524  INFO 2756 --- [-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:40:03.529  INFO 2756 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 1 (__consumer_offsets-0)
2019-06-25 18:40:03.530  INFO 2756 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group sender with generation 2 is now empty (__consumer_offsets-0)
2019-06-25 18:40:03.557  INFO 2756 --- [-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:40:03.578  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:40:03.579  INFO 2756 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 1 (__consumer_offsets-2)
2019-06-25 18:40:03.580  INFO 2756 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group helloworld with generation 2 is now empty (__consumer_offsets-2)
2019-06-25 18:40:03.584  INFO 2756 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:40:03.586  INFO 2756 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-06-25 18:40:03.588  INFO 2756 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-06-25 18:40:03.591  INFO 2756 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:40:03.594  INFO 2756 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 18:40:03.600  INFO 2756 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 18:40:03.602  INFO 2756 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2019-06-25 18:40:03.603  INFO 2756 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Starting controlled shutdown
2019-06-25 18:40:03.620  INFO 2756 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] Shutting down broker 0
2019-06-25 18:40:03.626  INFO 2756 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Controlled shutdown succeeded
2019-06-25 18:40:03.629  INFO 2756 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2019-06-25 18:40:03.631  INFO 2756 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2019-06-25 18:40:03.631  INFO 2756 --- [/config/changes-event-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2019-06-25 18:40:03.632  INFO 2756 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopping socket server request processors
2019-06-25 18:40:03.646  INFO 2756 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopped socket server request processors
2019-06-25 18:40:03.647  INFO 2756 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shutting down
2019-06-25 18:40:03.653  INFO 2756 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shut down completely
2019-06-25 18:40:03.658  INFO 2756 --- [main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2019-06-25 18:40:03.659  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2019-06-25 18:40:03.760  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2019-06-25 18:40:03.760  INFO 2756 --- [ExpirationReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2019-06-25 18:40:03.762  INFO 2756 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2019-06-25 18:40:03.764  INFO 2756 --- [main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2019-06-25 18:40:03.765  INFO 2756 --- [main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2019-06-25 18:40:03.765  INFO 2756 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutting down
2019-06-25 18:40:03.765  INFO 2756 --- [TxnMarkerSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Stopped
2019-06-25 18:40:03.765  INFO 2756 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutdown completed
2019-06-25 18:40:03.766  INFO 2756 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2019-06-25 18:40:03.767  INFO 2756 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2019-06-25 18:40:03.768  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2019-06-25 18:40:03.860  INFO 2756 --- [ExpirationReaper-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2019-06-25 18:40:03.860  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2019-06-25 18:40:03.860  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2019-06-25 18:40:04.009  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2019-06-25 18:40:04.009  INFO 2756 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2019-06-25 18:40:04.009  INFO 2756 --- [ExpirationReaper-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2019-06-25 18:40:04.011  INFO 2756 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2019-06-25 18:40:04.012  INFO 2756 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2019-06-25 18:40:04.012  INFO 2756 --- [LogDirFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2019-06-25 18:40:04.012  INFO 2756 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2019-06-25 18:40:04.013  INFO 2756 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2019-06-25 18:40:04.015  INFO 2756 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2019-06-25 18:40:04.016  INFO 2756 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutting down
2019-06-25 18:40:04.016  INFO 2756 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2019-06-25 18:40:04.016  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2019-06-25 18:40:04.069  INFO 2756 --- [ExpirationReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2019-06-25 18:40:04.069  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2019-06-25 18:40:04.069  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2019-06-25 18:40:04.166  INFO 2756 --- [ExpirationReaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2019-06-25 18:40:04.166  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2019-06-25 18:40:04.166  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2019-06-25 18:40:04.366  INFO 2756 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2019-06-25 18:40:04.367  INFO 2756 --- [ExpirationReaper-0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2019-06-25 18:40:04.437  INFO 2756 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2019-06-25 18:40:04.439  INFO 2756 --- [main] kafka.log.LogManager                     : Shutting down.
2019-06-25 18:40:04.441  INFO 2756 --- [main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2019-06-25 18:40:04.441  INFO 2756 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2019-06-25 18:40:04.442  INFO 2756 --- [kafka-log-cleaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2019-06-25 18:40:04.442  INFO 2756 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2019-06-25 18:40:04.570  INFO 2756 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=helloworld.t-0] Writing producer snapshot at offset 1
2019-06-25 18:40:04.752  INFO 2756 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 55
2019-06-25 18:40:04.776  INFO 2756 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 4
2019-06-25 18:40:04.968  INFO 2756 --- [main] kafka.log.LogManager                     : Shutdown complete.
2019-06-25 18:40:04.968  INFO 2756 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2019-06-25 18:40:04.969  INFO 2756 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2019-06-25 18:40:04.969  INFO 2756 --- [main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2019-06-25 18:40:04.972  INFO 2756 --- [main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=0] Stopped partition state machine
2019-06-25 18:40:04.974  INFO 2756 --- [main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2019-06-25 18:40:04.974  INFO 2756 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2019-06-25 18:40:04.975  INFO 2756 --- [Controller-0-to-broker-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2019-06-25 18:40:04.975  INFO 2756 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2019-06-25 18:40:04.977  INFO 2756 --- [main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2019-06-25 18:40:04.978  INFO 2756 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2019-06-25 18:40:04.979  INFO 2756 --- [ProcessThread(sid:0 cport:61641):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100008c257d0001
2019-06-25 18:40:05.002  INFO 2756 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100008c257d0001 closed
2019-06-25 18:40:05.002  INFO 2756 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100008c257d0001
2019-06-25 18:40:05.003  INFO 2756 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61647 which had sessionid 0x100008c257d0001
2019-06-25 18:40:05.004  INFO 2756 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2019-06-25 18:40:05.005  INFO 2756 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2019-06-25 18:40:05.706  INFO 2756 --- [ThrottledChannelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2019-06-25 18:40:05.706  INFO 2756 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2019-06-25 18:40:05.706  INFO 2756 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2019-06-25 18:40:06.255  INFO 3256 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Starting SpringKafkaApplicationTest on DIN69001166 with PID 3256 (started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 18:40:06.257  INFO 3256 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : No active profile set, falling back to default profiles: default
2019-06-25 18:40:06.708  INFO 2756 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2019-06-25 18:40:06.708  INFO 2756 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2019-06-25 18:40:06.708  INFO 2756 --- [ThrottledChannelReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2019-06-25 18:40:07.096  INFO 3256 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 18:40:07.198  INFO 3256 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 95ms. Found 3 repository interfaces.
2019-06-25 18:40:07.593  INFO 3256 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$f40e5b60] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:40:07.702  INFO 3256 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$c4f40edc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:40:07.709  INFO 2756 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2019-06-25 18:40:07.710  INFO 2756 --- [ThrottledChannelReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2019-06-25 18:40:07.713  INFO 2756 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutting down socket server
2019-06-25 18:40:07.735  INFO 2756 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutdown completed
2019-06-25 18:40:07.739  INFO 2756 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2019-06-25 18:40:07.747  INFO 2756 --- [ZkClient-EventThread-23-127.0.0.1:61641] org.I0Itec.zkclient.ZkEventThread        : Terminate ZkClient event thread.
2019-06-25 18:40:07.751  INFO 2756 --- [ProcessThread(sid:0 cport:61641):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100008c257d0000
2019-06-25 18:40:07.768  INFO 3256 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 18:40:07.786  INFO 2756 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100008c257d0000 closed
2019-06-25 18:40:07.786  INFO 2756 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100008c257d0000
2019-06-25 18:40:07.787  INFO 2756 --- [main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2019-06-25 18:40:07.787  INFO 2756 --- [main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2019-06-25 18:40:07.788  INFO 2756 --- [main] o.a.z.server.PrepRequestProcessor        : Shutting down
2019-06-25 18:40:07.788  INFO 2756 --- [main] o.a.z.server.SyncRequestProcessor        : Shutting down
2019-06-25 18:40:07.788  INFO 2756 --- [ProcessThread(sid:0 cport:61641):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2019-06-25 18:40:07.790  WARN 2756 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Unable to read additional data from client sessionid 0x100008c257d0000, likely client has closed socket
2019-06-25 18:40:07.790  INFO 2756 --- [SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2019-06-25 18:40:07.791  INFO 2756 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61644 which had sessionid 0x100008c257d0000
2019-06-25 18:40:07.791  INFO 2756 --- [main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2019-06-25 18:40:07.800  INFO 2756 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2019-06-25 18:40:07.809  INFO 3256 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$205c49dd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:40:07.957  INFO 2756 --- [SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2019-06-25 18:40:08.159  INFO 3256 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 18:40:08.165  WARN 3256 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 18:40:08.402  INFO 3256 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 18:40:08.405  INFO 3256 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 18:40:08.494  INFO 3256 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 18:40:08.564  INFO 3256 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 18:40:08.567  INFO 3256 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 18:40:08.706  INFO 3256 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 18:40:08.826 ERROR 2756 --- [Thread-0] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-8673181956781824990

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-8673181956781824990\version-2\log.1: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:40:08.828 ERROR 2756 --- [Thread-3] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-3353932250018052818\helloworld.t-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:40:08.902  INFO 3256 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 18:40:09.596  WARN 3256 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) ~[junit-4.12.jar:4.12]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) ~[.cp/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 61 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 66 common frames omitted

2019-06-25 18:40:09.605  INFO 3256 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@3a225534'
2019-06-25 18:40:09.607  INFO 3256 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:40:09.907  INFO 3256 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 18:40:10.779  INFO 3256 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 18:40:10.836  WARN 3256 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 18:40:11.358  INFO 3256 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61712]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:40:11.395  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:40:11.395  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:40:11.405  INFO 3256 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: eBs1bhBxTTC3D3aKIn_klg
2019-06-25 18:40:11.423  INFO 3256 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61712]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:40:11.428  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:40:11.428  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:40:11.430  INFO 3256 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:40:11.445  INFO 3256 --- [main] com.cg.Lib.SpringKafkaApplicationTest    : Started SpringKafkaApplicationTest in 5.469 seconds (JVM running for 10.464)
2019-06-25 18:40:11.452  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: eBs1bhBxTTC3D3aKIn_klg
2019-06-25 18:40:11.478  INFO 3256 --- [ProcessThread(sid:0 cport:61700):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100009067080001 type:setData cxid:0x50 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-06-25 18:40:11.528  INFO 3256 --- [kafka-request-handler-6] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-06-25 18:40:11.647  INFO 3256 --- [kafka-request-handler-6] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-06-25 18:40:11.648  INFO 3256 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-06-25 18:40:11.648  INFO 3256 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:40:11.802  INFO 3256 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61712]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:40:11.810  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:40:11.810  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:40:11.817  INFO 3256 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: eBs1bhBxTTC3D3aKIn_klg
2019-06-25 18:40:11.823  INFO 3256 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:61712]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:40:11.827  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:40:11.827  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:40:11.827  INFO 3256 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:40:11.851  INFO 3256 --- [-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: eBs1bhBxTTC3D3aKIn_klg
2019-06-25 18:40:11.851  INFO 3256 --- [kafka-request-handler-4] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:40:11.871  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Loading producer state till offset 0 with message format version 2
2019-06-25 18:40:11.874  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms
2019-06-25 18:40:11.876  INFO 3256 --- [kafka-request-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:40:11.877  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-06-25 18:40:11.877  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-06-25 18:40:11.877  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:40:11.949  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Loading producer state till offset 0 with message format version 2
2019-06-25 18:40:11.956  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms
2019-06-25 18:40:11.957  INFO 3256 --- [kafka-request-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:40:11.958  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-06-25 18:40:11.959  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-06-25 18:40:11.959  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:40:12.027  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Loading producer state till offset 0 with message format version 2
2019-06-25 18:40:12.030  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms
2019-06-25 18:40:12.030  INFO 3256 --- [kafka-request-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:40:12.031  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-06-25 18:40:12.031  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-06-25 18:40:12.031  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:40:12.110  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Loading producer state till offset 0 with message format version 2
2019-06-25 18:40:12.112  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2019-06-25 18:40:12.113  INFO 3256 --- [kafka-request-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:40:12.114  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-06-25 18:40:12.114  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-06-25 18:40:12.114  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:40:12.182  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Loading producer state till offset 0 with message format version 2
2019-06-25 18:40:12.186  INFO 3256 --- [kafka-request-handler-4] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms
2019-06-25 18:40:12.187  INFO 3256 --- [kafka-request-handler-4] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:40:12.188  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-06-25 18:40:12.188  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-06-25 18:40:12.188  INFO 3256 --- [kafka-request-handler-4] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:40:12.237  INFO 3256 --- [kafka-request-handler-4] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:40:12.239  INFO 3256 --- [kafka-request-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-06-25 18:40:12.240  INFO 3256 --- [kafka-request-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-06-25 18:40:12.240  INFO 3256 --- [kafka-request-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-06-25 18:40:12.240  INFO 3256 --- [kafka-request-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-06-25 18:40:12.240  INFO 3256 --- [kafka-request-handler-4] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-06-25 18:40:12.249  INFO 3256 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds.
2019-06-25 18:40:12.250  INFO 3256 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2019-06-25 18:40:12.250  INFO 3256 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2019-06-25 18:40:12.250  INFO 3256 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-06-25 18:40:12.250  INFO 3256 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2019-06-25 18:40:12.266  INFO 3256 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Discovered group coordinator localhost:61712 (id: 2147483647 rack: null)
2019-06-25 18:40:12.269  INFO 3256 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Revoking previously assigned partitions []
2019-06-25 18:40:12.269  INFO 3256 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:40:12.270  INFO 3256 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] (Re-)joining group
2019-06-25 18:40:12.285  INFO 3256 --- [kafka-request-handler-1] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 0 (__consumer_offsets-0)
2019-06-25 18:40:12.289  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Discovered group coordinator localhost:61712 (id: 2147483647 rack: null)
2019-06-25 18:40:12.292  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Revoking previously assigned partitions []
2019-06-25 18:40:12.292  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:40:12.292  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] (Re-)joining group
2019-06-25 18:40:12.295  INFO 3256 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 0 (__consumer_offsets-2)
2019-06-25 18:40:12.301  INFO 3256 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group sender generation 1 (__consumer_offsets-0)
2019-06-25 18:40:12.313  INFO 3256 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group sender for generation 1
2019-06-25 18:40:12.313  INFO 3256 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group helloworld generation 1 (__consumer_offsets-2)
2019-06-25 18:40:12.318  INFO 3256 --- [kafka-request-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group helloworld for generation 1
2019-06-25 18:40:12.370  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Successfully joined group with generation 1
2019-06-25 18:40:12.370  INFO 3256 --- [-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Successfully joined group with generation 1
2019-06-25 18:40:12.372  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Setting newly assigned partitions [helloworld.t-0, helloworld.t-1]
2019-06-25 18:40:12.372  INFO 3256 --- [-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-4, groupId=sender] Setting newly assigned partitions [helloworld.t-0, helloworld.t-1]
2019-06-25 18:40:12.385  INFO 3256 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:40:12.385  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:40:12.385  INFO 3256 --- [-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-4, groupId=sender] Resetting offset for partition helloworld.t-1 to offset 0.
2019-06-25 18:40:12.385  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-1 to offset 0.
2019-06-25 18:40:12.387  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0, helloworld.t-1]
2019-06-25 18:40:12.398  INFO 3256 --- [-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0, helloworld.t-1]
2019-06-25 18:40:12.414  INFO 3256 --- [main] com.cg.Lib.producer.Sender               : sending payload='Hello Spring Kafka Sender!'
2019-06-25 18:40:12.419  INFO 3256 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:61712]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-25 18:40:12.438  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:40:12.438  INFO 3256 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:40:12.444  INFO 3256 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: eBs1bhBxTTC3D3aKIn_klg
2019-06-25 18:40:12.498  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.cg.Lib.consumer.Receiver             : received payload='Hello Spring Kafka Sender!'
2019-06-25 18:40:12.522  INFO 3256 --- [-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:40:12.526  INFO 3256 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 1 (__consumer_offsets-0)
2019-06-25 18:40:12.527  INFO 3256 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group sender with generation 2 is now empty (__consumer_offsets-0)
2019-06-25 18:40:12.532  INFO 3256 --- [-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:40:12.540  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:40:12.543  INFO 3256 --- [kafka-request-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 1 (__consumer_offsets-2)
2019-06-25 18:40:12.543  INFO 3256 --- [kafka-request-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group helloworld with generation 2 is now empty (__consumer_offsets-2)
2019-06-25 18:40:12.546  INFO 3256 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:40:12.548  INFO 3256 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-06-25 18:40:12.548  INFO 3256 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-06-25 18:40:12.552  INFO 3256 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:40:12.554  INFO 3256 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 18:40:12.565  INFO 3256 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 18:40:12.566  INFO 3256 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2019-06-25 18:40:12.567  INFO 3256 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Starting controlled shutdown
2019-06-25 18:40:12.580  INFO 3256 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] Shutting down broker 0
2019-06-25 18:40:12.586  INFO 3256 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Controlled shutdown succeeded
2019-06-25 18:40:12.589  INFO 3256 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2019-06-25 18:40:12.590  INFO 3256 --- [/config/changes-event-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2019-06-25 18:40:12.590  INFO 3256 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2019-06-25 18:40:12.591  INFO 3256 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopping socket server request processors
2019-06-25 18:40:12.601  INFO 3256 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopped socket server request processors
2019-06-25 18:40:12.602  INFO 3256 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shutting down
2019-06-25 18:40:12.605  INFO 3256 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shut down completely
2019-06-25 18:40:12.608  INFO 3256 --- [main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2019-06-25 18:40:12.610  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2019-06-25 18:40:12.703  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2019-06-25 18:40:12.703  INFO 3256 --- [ExpirationReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2019-06-25 18:40:12.705  INFO 3256 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2019-06-25 18:40:12.706  INFO 3256 --- [main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2019-06-25 18:40:12.706  INFO 3256 --- [main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2019-06-25 18:40:12.706  INFO 3256 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutting down
2019-06-25 18:40:12.707  INFO 3256 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutdown completed
2019-06-25 18:40:12.707  INFO 3256 --- [TxnMarkerSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Stopped
2019-06-25 18:40:12.708  INFO 3256 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2019-06-25 18:40:12.708  INFO 3256 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2019-06-25 18:40:12.709  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2019-06-25 18:40:12.903  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2019-06-25 18:40:12.903  INFO 3256 --- [ExpirationReaper-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2019-06-25 18:40:12.903  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2019-06-25 18:40:13.104  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2019-06-25 18:40:13.104  INFO 3256 --- [ExpirationReaper-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2019-06-25 18:40:13.105  INFO 3256 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2019-06-25 18:40:13.106  INFO 3256 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2019-06-25 18:40:13.106  INFO 3256 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2019-06-25 18:40:13.107  INFO 3256 --- [LogDirFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2019-06-25 18:40:13.107  INFO 3256 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2019-06-25 18:40:13.107  INFO 3256 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2019-06-25 18:40:13.110  INFO 3256 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2019-06-25 18:40:13.110  INFO 3256 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutting down
2019-06-25 18:40:13.111  INFO 3256 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2019-06-25 18:40:13.111  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2019-06-25 18:40:13.224  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2019-06-25 18:40:13.224  INFO 3256 --- [ExpirationReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2019-06-25 18:40:13.224  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2019-06-25 18:40:13.305  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2019-06-25 18:40:13.305  INFO 3256 --- [ExpirationReaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2019-06-25 18:40:13.305  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2019-06-25 18:40:13.506  INFO 3256 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2019-06-25 18:40:13.506  INFO 3256 --- [ExpirationReaper-0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2019-06-25 18:40:13.548  INFO 3256 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2019-06-25 18:40:13.549  INFO 3256 --- [main] kafka.log.LogManager                     : Shutting down.
2019-06-25 18:40:13.550  INFO 3256 --- [main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2019-06-25 18:40:13.551  INFO 3256 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2019-06-25 18:40:13.551  INFO 3256 --- [kafka-log-cleaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2019-06-25 18:40:13.551  INFO 3256 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2019-06-25 18:40:13.647  INFO 3256 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=helloworld.t-0] Writing producer snapshot at offset 1
2019-06-25 18:40:13.739  INFO 3256 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 2
2019-06-25 18:40:13.847  INFO 3256 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 5
2019-06-25 18:40:14.068  INFO 3256 --- [main] kafka.log.LogManager                     : Shutdown complete.
2019-06-25 18:40:14.069  INFO 3256 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2019-06-25 18:40:14.069  INFO 3256 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2019-06-25 18:40:14.069  INFO 3256 --- [main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2019-06-25 18:40:14.072  INFO 3256 --- [main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=0] Stopped partition state machine
2019-06-25 18:40:14.074  INFO 3256 --- [main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2019-06-25 18:40:14.074  INFO 3256 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2019-06-25 18:40:14.074  INFO 3256 --- [Controller-0-to-broker-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2019-06-25 18:40:14.074  INFO 3256 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2019-06-25 18:40:14.076  INFO 3256 --- [main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2019-06-25 18:40:14.077  INFO 3256 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2019-06-25 18:40:14.078  INFO 3256 --- [ProcessThread(sid:0 cport:61700):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100009067080001
2019-06-25 18:40:14.102  INFO 3256 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100009067080001 closed
2019-06-25 18:40:14.102  INFO 3256 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100009067080001
2019-06-25 18:40:14.104  INFO 3256 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61706 which had sessionid 0x100009067080001
2019-06-25 18:40:14.104  INFO 3256 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2019-06-25 18:40:14.105  INFO 3256 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2019-06-25 18:40:14.349  INFO 3256 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2019-06-25 18:40:14.349  INFO 3256 --- [ThrottledChannelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2019-06-25 18:40:14.349  INFO 3256 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2019-06-25 18:40:14.350  INFO 3256 --- [ThrottledChannelReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2019-06-25 18:40:14.350  INFO 3256 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2019-06-25 18:40:14.350  INFO 3256 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2019-06-25 18:40:15.344  INFO 3256 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2019-06-25 18:40:15.344  INFO 3256 --- [ThrottledChannelReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2019-06-25 18:40:15.347  INFO 3256 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutting down socket server
2019-06-25 18:40:15.373  INFO 3256 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutdown completed
2019-06-25 18:40:15.376  INFO 3256 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2019-06-25 18:40:15.382  INFO 3256 --- [ZkClient-EventThread-20-127.0.0.1:61700] org.I0Itec.zkclient.ZkEventThread        : Terminate ZkClient event thread.
2019-06-25 18:40:15.383  INFO 3256 --- [ProcessThread(sid:0 cport:61700):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100009067080000
2019-06-25 18:40:15.402  INFO 3256 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100009067080000
2019-06-25 18:40:15.402  INFO 3256 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100009067080000 closed
2019-06-25 18:40:15.402  INFO 3256 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61703 which had sessionid 0x100009067080000
2019-06-25 18:40:15.403  INFO 3256 --- [main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2019-06-25 18:40:15.403  INFO 3256 --- [main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2019-06-25 18:40:15.403  INFO 3256 --- [main] o.a.z.server.PrepRequestProcessor        : Shutting down
2019-06-25 18:40:15.403  INFO 3256 --- [main] o.a.z.server.SyncRequestProcessor        : Shutting down
2019-06-25 18:40:15.403  INFO 3256 --- [ProcessThread(sid:0 cport:61700):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2019-06-25 18:40:15.403  INFO 3256 --- [SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2019-06-25 18:40:15.404  INFO 3256 --- [main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2019-06-25 18:40:15.407  INFO 3256 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2019-06-25 18:40:15.435  INFO 3256 --- [SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2019-06-25 18:40:16.424 ERROR 3256 --- [Thread-0] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-16076089007139055227

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-16076089007139055227\version-2\log.1: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:40:16.424 ERROR 3256 --- [Thread-3] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-3398559050151010637\helloworld.t-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:43:01.093  INFO 4340 --- [main] c.c.L.SpringKafkaReceiverApplicationTest : Starting SpringKafkaReceiverApplicationTest on DIN69001166 with PID 4340 (started by agunture in C:\Users\agunture\Desktop\LatestlIB-master\Lib)
2019-06-25 18:43:01.094  INFO 4340 --- [main] c.c.L.SpringKafkaReceiverApplicationTest : No active profile set, falling back to default profiles: default
2019-06-25 18:43:01.884  INFO 4340 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-25 18:43:01.974  INFO 4340 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 83ms. Found 3 repository interfaces.
2019-06-25 18:43:02.318  INFO 4340 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$9a69db7d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:43:02.420  INFO 4340 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.ws.config.annotation.DelegatingWsConfiguration' of type [org.springframework.ws.config.annotation.DelegatingWsConfiguration$$EnhancerBySpringCGLIB$$6b4f8ef9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:43:02.456  INFO 4340 --- [main] .w.s.a.s.AnnotationActionEndpointMapping : Supporting [WS-Addressing August 2004, WS-Addressing 1.0]
2019-06-25 18:43:02.480  INFO 4340 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c6b7c9fa] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-25 18:43:02.715  INFO 4340 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2019-06-25 18:43:02.719  WARN 4340 --- [main] com.zaxxer.hikari.util.DriverDataSource  : Registered driver with driverClassName=org.hsqldb.jdbcDriver was not found, trying direct instantiation.
2019-06-25 18:43:02.955  INFO 4340 --- [main] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Driver does not support get/set network timeout for connections. (feature not supported)
2019-06-25 18:43:02.957  INFO 4340 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2019-06-25 18:43:03.037  INFO 4340 --- [main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2019-06-25 18:43:03.107  INFO 4340 --- [main] org.hibernate.Version                    : HHH000412: Hibernate Core {5.3.9.Final}
2019-06-25 18:43:03.109  INFO 4340 --- [main] org.hibernate.cfg.Environment            : HHH000206: hibernate.properties not found
2019-06-25 18:43:03.247  INFO 4340 --- [main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.0.4.Final}
2019-06-25 18:43:03.389  INFO 4340 --- [main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.hibernate.dialect.HSQLDialect
2019-06-25 18:43:04.036  WARN 4340 --- [main] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement

org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL "alter table books_registration drop constraint FK9ib61f3v7y9dvvygrqnsbk2f8" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.applyConstraintDropping(SchemaDropperImpl.java:331) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:230) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:144) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:939) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:57) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:390) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:377) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.afterPropertiesSet(LocalContainerEntityManagerFactoryBean.java:341) ~[spring-orm-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1105) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.4.RELEASE.jar:2.1.4.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) ~[junit-4.12.jar:4.12]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) ~[junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) ~[.cp/:na]
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) ~[.cp/:na]
Caused by: java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.fetchResult(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.jdbc.JDBCStatement.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.2.0.jar:na]
	at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.2.0.jar:na]
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.3.9.Final.jar:5.3.9.Final]
	... 61 common frames omitted
Caused by: org.hsqldb.HsqlException: user lacks privilege or object not found: PUBLIC.BOOKS_REGISTRATION
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.error.Error.error(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.SchemaManager.getUserTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlterTable(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserDDL.compileAlter(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compilePart(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.ParserCommand.compileStatements(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.executeDirectStatement(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	at org.hsqldb.Session.execute(Unknown Source) ~[hsqldb-2.4.1.jar:2.4.1]
	... 66 common frames omitted

2019-06-25 18:43:04.048  INFO 4340 --- [main] o.h.t.schema.internal.SchemaCreatorImpl  : HHH000476: Executing import script 'org.hibernate.tool.schema.internal.exec.ScriptSourceInputNonExistentImpl@feab3ae'
2019-06-25 18:43:04.051  INFO 4340 --- [main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:43:04.373  INFO 4340 --- [main] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory
2019-06-25 18:43:05.216  INFO 4340 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-06-25 18:43:05.273  WARN 4340 --- [main] aWebConfiguration$JpaWebMvcConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2019-06-25 18:43:05.790  INFO 4340 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61778]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:43:05.831  INFO 4340 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:43:05.832  INFO 4340 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:43:05.840  INFO 4340 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: fGhq7HxfQ3G5S9aL4enXaw
2019-06-25 18:43:05.858  INFO 4340 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:61778]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = helloworld
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-06-25 18:43:05.862  INFO 4340 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:43:05.862  INFO 4340 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:43:05.865  INFO 4340 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-06-25 18:43:05.878  INFO 4340 --- [main] c.c.L.SpringKafkaReceiverApplicationTest : Started SpringKafkaReceiverApplicationTest in 5.111 seconds (JVM running for 9.693)
2019-06-25 18:43:05.884  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: fGhq7HxfQ3G5S9aL4enXaw
2019-06-25 18:43:05.918  INFO 4340 --- [ProcessThread(sid:0 cport:61769):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100009313100001 type:setData cxid:0x50 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-06-25 18:43:06.025  INFO 4340 --- [kafka-request-handler-4] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-06-25 18:43:06.047  INFO 4340 --- [kafka-request-handler-4] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-06-25 18:43:06.050  INFO 4340 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-06-25 18:43:06.051  INFO 4340 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:43:06.184  INFO 4340 --- [kafka-request-handler-5] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-06-25 18:43:06.210  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Loading producer state till offset 0 with message format version 2
2019-06-25 18:43:06.213  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms
2019-06-25 18:43:06.214  INFO 4340 --- [kafka-request-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:43:06.216  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-06-25 18:43:06.216  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-06-25 18:43:06.216  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:43:06.276  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Loading producer state till offset 0 with message format version 2
2019-06-25 18:43:06.278  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms
2019-06-25 18:43:06.279  INFO 4340 --- [kafka-request-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:43:06.280  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-06-25 18:43:06.280  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-06-25 18:43:06.281  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:43:06.375  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Loading producer state till offset 0 with message format version 2
2019-06-25 18:43:06.378  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms
2019-06-25 18:43:06.379  INFO 4340 --- [kafka-request-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:43:06.379  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-06-25 18:43:06.380  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-06-25 18:43:06.380  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:43:06.500  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Loading producer state till offset 0 with message format version 2
2019-06-25 18:43:06.507  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms
2019-06-25 18:43:06.509  INFO 4340 --- [kafka-request-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:43:06.511  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-06-25 18:43:06.512  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-06-25 18:43:06.512  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:43:06.619  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Loading producer state till offset 0 with message format version 2
2019-06-25 18:43:06.626  INFO 4340 --- [kafka-request-handler-5] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms
2019-06-25 18:43:06.627  INFO 4340 --- [kafka-request-handler-5] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-06-25 18:43:06.629  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-06-25 18:43:06.629  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-06-25 18:43:06.629  INFO 4340 --- [kafka-request-handler-5] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-06-25 18:43:06.680  INFO 4340 --- [kafka-request-handler-5] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-06-25 18:43:06.685  INFO 4340 --- [kafka-request-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-06-25 18:43:06.687  INFO 4340 --- [kafka-request-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-06-25 18:43:06.688  INFO 4340 --- [kafka-request-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-06-25 18:43:06.688  INFO 4340 --- [kafka-request-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-06-25 18:43:06.688  INFO 4340 --- [kafka-request-handler-5] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-06-25 18:43:06.710  INFO 4340 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 23 milliseconds.
2019-06-25 18:43:06.712  INFO 4340 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
2019-06-25 18:43:06.713  INFO 4340 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds.
2019-06-25 18:43:06.713  INFO 4340 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-06-25 18:43:06.714  INFO 4340 --- [group-metadata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds.
2019-06-25 18:43:06.785  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Discovered group coordinator localhost:61778 (id: 2147483647 rack: null)
2019-06-25 18:43:06.793  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Revoking previously assigned partitions []
2019-06-25 18:43:06.794  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-06-25 18:43:06.795  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] (Re-)joining group
2019-06-25 18:43:06.832  INFO 4340 --- [kafka-request-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 0 (__consumer_offsets-2)
2019-06-25 18:43:06.842  INFO 4340 --- [executor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group helloworld generation 1 (__consumer_offsets-2)
2019-06-25 18:43:06.853  INFO 4340 --- [kafka-request-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group helloworld for generation 1
2019-06-25 18:43:06.895  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Successfully joined group with generation 1
2019-06-25 18:43:06.897  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=helloworld] Setting newly assigned partitions [helloworld.t-0, helloworld.t-1]
2019-06-25 18:43:06.919  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-0 to offset 0.
2019-06-25 18:43:06.919  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=helloworld] Resetting offset for partition helloworld.t-1 to offset 0.
2019-06-25 18:43:06.920  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [helloworld.t-0, helloworld.t-1]
2019-06-25 18:43:06.944  INFO 4340 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:61778]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-25 18:43:06.959  INFO 4340 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-06-25 18:43:06.959  INFO 4340 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-06-25 18:43:06.965  INFO 4340 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: fGhq7HxfQ3G5S9aL4enXaw
2019-06-25 18:43:07.012  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.cg.Lib.consumer.Receiver             : received payload='Hello Spring Kafka Receiver!'
2019-06-25 18:43:07.025  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-06-25 18:43:07.028  INFO 4340 --- [kafka-request-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group helloworld with old generation 1 (__consumer_offsets-2)
2019-06-25 18:43:07.029  INFO 4340 --- [kafka-request-handler-5] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group helloworld with generation 2 is now empty (__consumer_offsets-2)
2019-06-25 18:43:07.033  INFO 4340 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-06-25 18:43:07.035  INFO 4340 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-06-25 18:43:07.037  INFO 4340 --- [main] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2019-06-25 18:43:07.038  INFO 4340 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2019-06-25 18:43:07.043  INFO 4340 --- [main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
2019-06-25 18:43:07.044  INFO 4340 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2019-06-25 18:43:07.045  INFO 4340 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Starting controlled shutdown
2019-06-25 18:43:07.056  INFO 4340 --- [controller-event-thread] kafka.controller.KafkaController         : [Controller id=0] Shutting down broker 0
2019-06-25 18:43:07.061  INFO 4340 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] Controlled shutdown succeeded
2019-06-25 18:43:07.064  INFO 4340 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2019-06-25 18:43:07.064  INFO 4340 --- [main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2019-06-25 18:43:07.064  INFO 4340 --- [/config/changes-event-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2019-06-25 18:43:07.065  INFO 4340 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopping socket server request processors
2019-06-25 18:43:07.076  INFO 4340 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopped socket server request processors
2019-06-25 18:43:07.077  INFO 4340 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shutting down
2019-06-25 18:43:07.079  INFO 4340 --- [main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shut down completely
2019-06-25 18:43:07.083  INFO 4340 --- [main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2019-06-25 18:43:07.084  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2019-06-25 18:43:07.227  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2019-06-25 18:43:07.227  INFO 4340 --- [ExpirationReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2019-06-25 18:43:07.231  INFO 4340 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2019-06-25 18:43:07.233  INFO 4340 --- [main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2019-06-25 18:43:07.234  INFO 4340 --- [main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2019-06-25 18:43:07.234  INFO 4340 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutting down
2019-06-25 18:43:07.237  INFO 4340 --- [TxnMarkerSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Stopped
2019-06-25 18:43:07.237  INFO 4340 --- [main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutdown completed
2019-06-25 18:43:07.238  INFO 4340 --- [main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2019-06-25 18:43:07.240  INFO 4340 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2019-06-25 18:43:07.241  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2019-06-25 18:43:07.429  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2019-06-25 18:43:07.429  INFO 4340 --- [ExpirationReaper-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2019-06-25 18:43:07.429  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2019-06-25 18:43:07.441  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2019-06-25 18:43:07.441  INFO 4340 --- [ExpirationReaper-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2019-06-25 18:43:07.442  INFO 4340 --- [main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2019-06-25 18:43:07.443  INFO 4340 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2019-06-25 18:43:07.443  INFO 4340 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2019-06-25 18:43:07.443  INFO 4340 --- [LogDirFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2019-06-25 18:43:07.443  INFO 4340 --- [main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2019-06-25 18:43:07.443  INFO 4340 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2019-06-25 18:43:07.445  INFO 4340 --- [main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2019-06-25 18:43:07.445  INFO 4340 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutting down
2019-06-25 18:43:07.445  INFO 4340 --- [main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2019-06-25 18:43:07.445  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2019-06-25 18:43:07.516  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2019-06-25 18:43:07.516  INFO 4340 --- [ExpirationReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2019-06-25 18:43:07.516  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2019-06-25 18:43:07.628  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2019-06-25 18:43:07.628  INFO 4340 --- [ExpirationReaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2019-06-25 18:43:07.628  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2019-06-25 18:43:07.829  INFO 4340 --- [main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2019-06-25 18:43:07.829  INFO 4340 --- [ExpirationReaper-0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2019-06-25 18:43:07.866  INFO 4340 --- [main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2019-06-25 18:43:07.867  INFO 4340 --- [main] kafka.log.LogManager                     : Shutting down.
2019-06-25 18:43:07.868  INFO 4340 --- [main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2019-06-25 18:43:07.868  INFO 4340 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2019-06-25 18:43:07.869  INFO 4340 --- [kafka-log-cleaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2019-06-25 18:43:07.869  INFO 4340 --- [main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2019-06-25 18:43:07.965  INFO 4340 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=helloworld.t-0] Writing producer snapshot at offset 1
2019-06-25 18:43:08.044  INFO 4340 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 2
2019-06-25 18:43:08.179  WARN 4340 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-1] Connection to node 0 could not be established. Broker may not be available.
2019-06-25 18:43:08.228  INFO 4340 --- [main] kafka.log.LogManager                     : Shutdown complete.
2019-06-25 18:43:08.229  INFO 4340 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2019-06-25 18:43:08.229  INFO 4340 --- [controller-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2019-06-25 18:43:08.229  INFO 4340 --- [main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2019-06-25 18:43:08.231  INFO 4340 --- [main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=0] Stopped partition state machine
2019-06-25 18:43:08.233  INFO 4340 --- [main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2019-06-25 18:43:08.233  INFO 4340 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2019-06-25 18:43:08.233  INFO 4340 --- [Controller-0-to-broker-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2019-06-25 18:43:08.233  INFO 4340 --- [main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2019-06-25 18:43:08.235  INFO 4340 --- [main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2019-06-25 18:43:08.236  INFO 4340 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2019-06-25 18:43:08.237  INFO 4340 --- [ProcessThread(sid:0 cport:61769):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100009313100001
2019-06-25 18:43:08.273  INFO 4340 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100009313100001 closed
2019-06-25 18:43:08.273  INFO 4340 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100009313100001
2019-06-25 18:43:08.273  WARN 4340 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Unable to read additional data from client sessionid 0x100009313100001, likely client has closed socket
2019-06-25 18:43:08.274  INFO 4340 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61775 which had sessionid 0x100009313100001
2019-06-25 18:43:08.275  INFO 4340 --- [main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2019-06-25 18:43:08.275  INFO 4340 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2019-06-25 18:43:08.418  INFO 4340 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2019-06-25 18:43:08.418  INFO 4340 --- [ThrottledChannelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2019-06-25 18:43:08.418  INFO 4340 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2019-06-25 18:43:09.281  WARN 4340 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-1] Connection to node 0 could not be established. Broker may not be available.
2019-06-25 18:43:09.418  INFO 4340 --- [ThrottledChannelReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2019-06-25 18:43:09.418  INFO 4340 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2019-06-25 18:43:09.419  INFO 4340 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2019-06-25 18:43:10.420  INFO 4340 --- [main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2019-06-25 18:43:10.420  INFO 4340 --- [ThrottledChannelReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2019-06-25 18:43:10.421  INFO 4340 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutting down socket server
2019-06-25 18:43:10.441  INFO 4340 --- [main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutdown completed
2019-06-25 18:43:10.444  INFO 4340 --- [main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2019-06-25 18:43:10.450  INFO 4340 --- [ZkClient-EventThread-20-127.0.0.1:61769] org.I0Itec.zkclient.ZkEventThread        : Terminate ZkClient event thread.
2019-06-25 18:43:10.451  INFO 4340 --- [ProcessThread(sid:0 cport:61769):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100009313100000
2019-06-25 18:43:10.512  INFO 4340 --- [main] org.apache.zookeeper.ZooKeeper           : Session: 0x100009313100000 closed
2019-06-25 18:43:10.512  INFO 4340 --- [main-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100009313100000
2019-06-25 18:43:10.513  INFO 4340 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:61772 which had sessionid 0x100009313100000
2019-06-25 18:43:10.513  INFO 4340 --- [main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2019-06-25 18:43:10.513  INFO 4340 --- [main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2019-06-25 18:43:10.513  INFO 4340 --- [main] o.a.z.server.PrepRequestProcessor        : Shutting down
2019-06-25 18:43:10.513  INFO 4340 --- [main] o.a.z.server.SyncRequestProcessor        : Shutting down
2019-06-25 18:43:10.513  INFO 4340 --- [ProcessThread(sid:0 cport:61769):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2019-06-25 18:43:10.514  INFO 4340 --- [SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2019-06-25 18:43:10.514  INFO 4340 --- [main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2019-06-25 18:43:10.518  INFO 4340 --- [NIOServerCxn.Factory:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
2019-06-25 18:43:10.535  WARN 4340 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-1] Connection to node 0 could not be established. Broker may not be available.
2019-06-25 18:43:10.936  INFO 4340 --- [SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
2019-06-25 18:43:11.545 ERROR 4340 --- [Thread-3] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-777094332722217194\helloworld.t-0\00000000000000000000.timeindex: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

2019-06-25 18:43:11.546 ERROR 4340 --- [Thread-0] org.apache.kafka.test.TestUtils          : Error deleting C:\Users\agunture\AppData\Local\Temp\kafka-6122558285729494285

java.nio.file.FileSystemException: C:\Users\agunture\AppData\Local\Temp\kafka-6122558285729494285\version-2\log.1: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[na:na]
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[na:na]
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:274) ~[na:na]
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105) ~[na:na]
	at java.base/java.nio.file.Files.delete(Files.java:1144) ~[na:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:734) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.common.utils.Utils$2.visitFile(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2801) ~[na:na]
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2873) ~[na:na]
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:723) ~[kafka-clients-2.0.1.jar:na]
	at org.apache.kafka.test.TestUtils$1.run(TestUtils.java:184) ~[kafka-clients-2.0.1-test.jar:na]

